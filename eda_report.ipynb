{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Top Entry Indicators",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Price Indicators",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Top Exit Indicators",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1881d7cc-a042-45b5-a1b8-d7472b81267a",
       "rows": [
        [
         "0",
         "KAMA",
         "ATR",
         "CloseM"
        ],
        [
         "1",
         "Low",
         "BiggestRange",
         "OpenM"
        ],
        [
         "2",
         "HeikenAshiHigh",
         "SmallestRange",
         "HighM"
        ],
        [
         "3",
         "ParabolicSAR",
         "BBRange",
         "LowM"
        ],
        [
         "4",
         "HeikenAshiLow",
         "BBWidthRatio",
         "HighW"
        ],
        [
         "5",
         "EMA",
         "BarRange",
         "OpenW"
        ],
        [
         "6",
         "HeikenAshiClose",
         "MTATR",
         "LowW"
        ],
        [
         "7",
         "KeltnerChannel",
         "HighD",
         "CloseW"
        ],
        [
         "8",
         "Open",
         "TrueRange",
         "KAMA"
        ],
        [
         "9",
         "HeikenAshiOpen",
         "OpenD",
         "CloseD"
        ],
        [
         "10",
         "LinearRegression",
         "Pivots",
         "VWAP"
        ],
        [
         "11",
         "Fractal",
         "Highest",
         "HeikenAshiHigh"
        ],
        [
         "12",
         "HullMovingAverage",
         "Low",
         "LinearRegression"
        ],
        [
         "13",
         "MTATR",
         "HighestInRange",
         "TEMA"
        ],
        [
         "14",
         "High",
         "HeikenAshiHigh",
         "LWMA"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Entry Indicators</th>\n",
       "      <th>Top Price Indicators</th>\n",
       "      <th>Top Exit Indicators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KAMA</td>\n",
       "      <td>ATR</td>\n",
       "      <td>CloseM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low</td>\n",
       "      <td>BiggestRange</td>\n",
       "      <td>OpenM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HeikenAshiHigh</td>\n",
       "      <td>SmallestRange</td>\n",
       "      <td>HighM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ParabolicSAR</td>\n",
       "      <td>BBRange</td>\n",
       "      <td>LowM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HeikenAshiLow</td>\n",
       "      <td>BBWidthRatio</td>\n",
       "      <td>HighW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EMA</td>\n",
       "      <td>BarRange</td>\n",
       "      <td>OpenW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HeikenAshiClose</td>\n",
       "      <td>MTATR</td>\n",
       "      <td>LowW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KeltnerChannel</td>\n",
       "      <td>HighD</td>\n",
       "      <td>CloseW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Open</td>\n",
       "      <td>TrueRange</td>\n",
       "      <td>KAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HeikenAshiOpen</td>\n",
       "      <td>OpenD</td>\n",
       "      <td>CloseD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>Pivots</td>\n",
       "      <td>VWAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fractal</td>\n",
       "      <td>Highest</td>\n",
       "      <td>HeikenAshiHigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HullMovingAverage</td>\n",
       "      <td>Low</td>\n",
       "      <td>LinearRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MTATR</td>\n",
       "      <td>HighestInRange</td>\n",
       "      <td>TEMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>High</td>\n",
       "      <td>HeikenAshiHigh</td>\n",
       "      <td>LWMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Top Entry Indicators Top Price Indicators Top Exit Indicators\n",
       "0                  KAMA                  ATR              CloseM\n",
       "1                   Low         BiggestRange               OpenM\n",
       "2        HeikenAshiHigh        SmallestRange               HighM\n",
       "3          ParabolicSAR              BBRange                LowM\n",
       "4         HeikenAshiLow         BBWidthRatio               HighW\n",
       "5                   EMA             BarRange               OpenW\n",
       "6       HeikenAshiClose                MTATR                LowW\n",
       "7        KeltnerChannel                HighD              CloseW\n",
       "8                  Open            TrueRange                KAMA\n",
       "9        HeikenAshiOpen                OpenD              CloseD\n",
       "10     LinearRegression               Pivots                VWAP\n",
       "11              Fractal              Highest      HeikenAshiHigh\n",
       "12    HullMovingAverage                  Low    LinearRegression\n",
       "13                MTATR       HighestInRange                TEMA\n",
       "14                 High       HeikenAshiHigh                LWMA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de configuración creado: /mnt/c/Users/Administrador/Downloads/Build Strategies.cfx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# --- PARÁMETROS Y FUNCIONES ---\n",
    "def process_indicators(csv_path, column_name):\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"El archivo '{csv_path}' no existe. Verifica la ruta base o el nombre del archivo.\")\n",
    "    df = pd.read_csv(csv_path, delimiter=';', encoding='utf-8')\n",
    "    expanded = df.assign(**{column_name: df[column_name].str.split(',')}).explode(column_name)\n",
    "    grouped = expanded.groupby(column_name).agg({\n",
    "        'Edge Ratio': 'mean',\n",
    "        'Ret/DD Ratio': 'mean',\n",
    "        'Profit factor': 'mean',\n",
    "        column_name: 'count'\n",
    "    }).rename(columns={\n",
    "        'Edge Ratio': 'Avg_EdgeRatio',\n",
    "        'Ret/DD Ratio': 'Avg_RetDD',\n",
    "        'Profit factor': 'Avg_ProfitFactor',\n",
    "        column_name: 'Count'\n",
    "    })\n",
    "    grouped['Score'] = (\n",
    "        grouped['Avg_EdgeRatio'] * 40 +\n",
    "        grouped['Avg_RetDD'] * 15 +\n",
    "        grouped['Avg_ProfitFactor'] * 15 +\n",
    "        grouped['Count'] * 30\n",
    "    )\n",
    "    return grouped.sort_values(by='Score', ascending=False).head(15).index.tolist()\n",
    "\n",
    "def matches_suffix(key, indicators_list):\n",
    "    return any(key.endswith(f\".{ind}\") for ind in indicators_list)\n",
    "\n",
    "def main():\n",
    "    # Asegurarse de que la carpeta existe\n",
    "    base_path = r\"/mnt/c/Users/Administrador/Downloads\"\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    # Archivos fijos dentro de la ruta proporcionada\n",
    "    csv_path = os.path.join(base_path, \"DatabankExport.csv\")\n",
    "    config_path = os.path.join(base_path, \"config.xml\")\n",
    "    output_path = os.path.join(base_path, \"Build Strategies.cfx\")\n",
    "    # Obtener los nombres de indicadores más prometedores\n",
    "    top_entry_indicators = process_indicators(csv_path, 'Entry indicators')\n",
    "    top_price_indicators = process_indicators(csv_path, 'Price indicators')\n",
    "    top_exit_indicators = process_indicators(csv_path, 'Exit indicators')\n",
    "    pf = pd.DataFrame({\n",
    "        'Top Entry Indicators': top_entry_indicators,\n",
    "        'Top Price Indicators': top_price_indicators,\n",
    "        'Top Exit Indicators': top_exit_indicators\n",
    "    })\n",
    "    display(pf)\n",
    "    essential_indicator_operators = [\n",
    "        \"CrossesAbove\", \"CrossesBelow\", \"IndicatorAboveMA\", \"IndicatorBelowMA\",\n",
    "        \"IndicatorCrossesAboveMA\", \"IndicatorCrossesBelowMA\",\n",
    "        \"IsRising\", \"IsFalling\", \"IsGreater\", \"IsGreaterOrEqual\",\n",
    "        \"IsLower\", \"IsLowerOrEqual\", \"Equals\", \"NotEquals\",\n",
    "        \"IsGreaterPercentil\", \"IsLowerPercentil\", \"IsGreaterCount\", \"IsLowerCount\", \"Not\"\n",
    "    ]\n",
    "\n",
    "    # --- XML MODIFICACIÓN ---\n",
    "    with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "        zip_ref.extract(\"config.xml\", path=base_path)\n",
    "    tree = ET.parse(config_path)\n",
    "    root = tree.getroot()\n",
    "    blocks_root = root.find(\".//BuildingBlocks\")\n",
    "    os.remove(config_path)\n",
    "\n",
    "    if blocks_root is not None:\n",
    "        for block in blocks_root.findall(\"Block\"):\n",
    "            key = block.attrib.get(\"key\", \"\")\n",
    "            category = block.attrib.get(\"category\", \"\").lower()\n",
    "\n",
    "            # Señales predefinidas\n",
    "            if category == \"signals\":\n",
    "                block.set(\"use\", \"true\")\n",
    "            \n",
    "            # Entry indicators y operadores\n",
    "            elif category == \"indicators\":\n",
    "                if key in essential_indicator_operators:\n",
    "                    block.set(\"use\", \"true\")\n",
    "                elif matches_suffix(key, top_entry_indicators):\n",
    "                    block.set(\"use\", \"true\")\n",
    "                elif matches_suffix(key, top_exit_indicators):\n",
    "                    block.set(\"use\", \"true\")\n",
    "                else:\n",
    "                    block.set(\"use\", \"false\")\n",
    "\n",
    "            # Price indicators\n",
    "            elif category == \"stoplimitblocks\":\n",
    "                if matches_suffix(key, top_price_indicators):\n",
    "                    block.set(\"use\", \"true\")\n",
    "                else:\n",
    "                    block.set(\"use\", \"false\")\n",
    "\n",
    "    # Guardar XML temporal en la ruta base\n",
    "    temp_xml = os.path.join(base_path, \"config_temp.xml\")\n",
    "    tree.write(temp_xml, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "    # Comprimir en .cfx dentro de la ruta base\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(temp_xml, arcname=\"config.xml\")\n",
    "    print(f\"Archivo de configuración creado: {output_path}\")\n",
    "    # Eliminar el archivo temporal\n",
    "    os.remove(temp_xml)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy Tester analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_xls_report(filename):\n",
    "    data = pd.read_excel(filename, header=None)\n",
    "    start_index = data[data.iloc[:, 0]=='Transacciones'].index[0]\n",
    "    end_index = data.iloc[start_index:, 0].isna().idxmax()\n",
    "    columns = data.iloc[start_index+1].tolist()\n",
    "    data.columns = columns\n",
    "    balance = data['Beneficio'].iloc[start_index+2]\n",
    "    data = data.iloc[start_index+3:end_index-1,:]\n",
    "    resultados = []\n",
    "    for i in range(0, len(data) - 1, 2):\n",
    "        fila_in = data.iloc[i]\n",
    "        fila_out = data.iloc[i + 1]\n",
    "        if fila_in['Dirección'] == 'in' and fila_out['Dirección'] == 'out':\n",
    "            precio_entrada = fila_in['Precio']\n",
    "            precio_salida = fila_out['Precio']\n",
    "            beneficio = fila_out['Beneficio'] - abs(fila_in['Comisión']) - abs(fila_out['Comisión'])\n",
    "            balance += beneficio\n",
    "            resultados.append({\n",
    "                'Fecha': fila_in['Fecha/Hora'],\n",
    "                'Símbolo': fila_in['Símbolo'],\n",
    "                'Tipo': fila_in['Tipo'],\n",
    "                'Precio Entrada': precio_entrada,\n",
    "                'Precio Salida': precio_salida,\n",
    "                'Volumen': fila_in['Volumen '],\n",
    "                'Beneficio': beneficio,\n",
    "                'Balance': balance\n",
    "            })\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "filename='ReportTester-4000009439.xlsx'\n",
    "# Statistics\n",
    "df = load_xls_report(filename)\n",
    "total_trades = df.shape[0]\n",
    "profit_trades = df[df['Beneficio']>0].shape[0]\n",
    "profit_avg = df[df['Beneficio']>0]['Beneficio'].mean()\n",
    "loss_trades = df[df['Beneficio']<0].shape[0]\n",
    "loss_avg = df[df['Beneficio']<0]['Beneficio'].mean()\n",
    "beneficio_neto  = (profit_avg*profit_trades)+(loss_avg*loss_trades)\n",
    "total_trades = profit_trades + loss_trades\n",
    "expected_profit = beneficio_neto / total_trades\n",
    "profit_avg_points = abs(df[df['Beneficio']>0]['Precio Entrada'] - df[df['Beneficio']>0]['Precio Salida']).mean() / 0.1\n",
    "loss_avg_points = abs(df[df['Beneficio']<0]['Precio Entrada'] - df[df['Beneficio']<0]['Precio Salida']).mean() / 0.1\n",
    "punto_equilibrio = abs(loss_avg)/(abs(loss_avg)+profit_avg)\n",
    "win_rates = profit_trades/total_trades\n",
    "balances = df['Balance']\n",
    "cummax_balance = balances.cummax()\n",
    "drawdowns = cummax_balance - balances\n",
    "drawdown_percentages = drawdowns / cummax_balance\n",
    "max_drawdown_percentage = drawdown_percentages.max() * 100\n",
    "\n",
    "print(f\"Número de operaciones totales: {total_trades}\")\n",
    "print(f\"Número de operaciones ganadoras: {profit_trades}\")\n",
    "print(f\"Número de operaciones perdedoras: {loss_trades}\")\n",
    "print(f\"Media de puntos en operaciones ganadoras {profit_avg_points:.2f} puntos\")\n",
    "print(f\"Media de puntos en operaciones perdedoras {loss_avg_points:.2f} puntos\")\n",
    "print(f\"Ganancia media: {profit_avg:.2f}€\")\n",
    "print(f\"Pérdida media: {loss_avg:.2f}€\")\n",
    "print(f\"Rentabilidad esperada: {expected_profit:.4f}€\")\n",
    "print(f\"Porcentaje de aciertos actual: {win_rates*100.0:.2f}%\")\n",
    "print(f\"Porcentaje de aciertos para equilibrio: {punto_equilibrio*100.0:.2f}%\")\n",
    "print(f\"El máximo drawdown es: {max_drawdown_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Optimization Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_mt5_optimization_report(xml_file_path):\n",
    "    \"\"\"\n",
    "    Parsea el reporte de optimización de MT5 exportado como XML (Excel 2003),\n",
    "    y devuelve un DataFrame con todas las configuraciones y sus métricas.\n",
    "    Versión mejorada con manejo de errores y compatibilidad con diferentes formatos MT5.\n",
    "    \"\"\"\n",
    "    with open(xml_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(content, features='xml')  # Usamos el parser XML nativo\n",
    "    \n",
    "    # Versión flexible para encontrar la hoja de resultados\n",
    "    worksheet_names = ['Tester Optimizator Results', 'Optimization Results', 'Results']\n",
    "    worksheet = None\n",
    "    \n",
    "    for name in worksheet_names:\n",
    "        worksheet = soup.find('Worksheet', {'ss:Name': name}) or soup.find('worksheet', {'ss:name': name})\n",
    "        if worksheet:\n",
    "            break\n",
    "    \n",
    "    if worksheet is None:\n",
    "        # Si no encontramos por nombre, buscamos cualquier hoja que contenga datos de optimización\n",
    "        worksheets = soup.find_all(['Worksheet', 'worksheet'])\n",
    "        for ws in worksheets:\n",
    "            if ws.find('Row') or ws.find('row'):\n",
    "                worksheet = ws\n",
    "                break\n",
    "    \n",
    "    if worksheet is None:\n",
    "        available_sheets = [ws.get('ss:Name') or ws.get('ss:name') for ws in soup.find_all(['Worksheet', 'worksheet'])]\n",
    "        raise ValueError(f\"No se encontró la hoja de resultados en el XML. Hojas disponibles: {available_sheets}\")\n",
    "\n",
    "    # Buscamos la tabla (con compatibilidad para mayúsculas/minúsculas)\n",
    "    table = worksheet.find(['Table', 'table'])\n",
    "    rows = table.find_all(['Row', 'row'], recursive=False)  # Buscamos solo filas directas\n",
    "    \n",
    "    if not rows:\n",
    "        raise ValueError(\"No se encontraron filas de datos en la hoja de resultados\")\n",
    "    \n",
    "    # Primera fila: nombres de columnas\n",
    "    headers = []\n",
    "    header_cells = rows[0].find_all(['Cell', 'cell'])\n",
    "    for cell in header_cells:\n",
    "        data = cell.find('Data', {'ss:Type': 'String'}) or cell.find('data')\n",
    "        headers.append(data.get_text(strip=True) if data else f\"Columna_{len(headers)+1}\")\n",
    "    \n",
    "    # Resto de filas: datos\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cells = row.find_all(['Cell', 'cell'])\n",
    "        row_values = []\n",
    "        for cell in cells:\n",
    "            data_elem = (cell.find(['Data', 'data']) or \n",
    "                         cell.find('Data', {'ss:Type': 'Number'}) or \n",
    "                         cell.find('Data', {'ss:Type': 'String'}))\n",
    "            row_values.append(data_elem.get_text(strip=True) if data_elem else '')\n",
    "        data.append(row_values)\n",
    "    \n",
    "    # Convertimos a DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    # Limpieza y conversión numérica\n",
    "    df = df.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
    "    df.replace('', pd.NA, inplace=True)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    \n",
    "    # Columnas numéricas comunes en MT5 (ajusta si hace falta)\n",
    "    numeric_cols = [\n",
    "        \"Pass\", \"Result\", \"Profit\", \"Expected Payoff\", \"Profit Factor\",\n",
    "        \"Recovery Factor\", \"Sharpe Ratio\", \"Custom\", \"Equity DD %\",\n",
    "        \"Trades\", \"max_orders\", \"orders_time_delay\", \"max_spread\",\n",
    "        \"stoploss\", \"takeprofit\"\n",
    "    ]\n",
    "    \n",
    "    # Convertimos solo las columnas que existan\n",
    "    numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
    "    for col in numeric_cols:\n",
    "        # Soporte a comas como separador decimal\n",
    "        df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def pareto_frontier(df, objectives):\n",
    "    \"\"\"\n",
    "    Retorna un subconjunto del DataFrame 'df' que conforma el frente de Pareto\n",
    "    bajo los objetivos indicados.\n",
    "\n",
    "    'objectives' es una lista de tuplas (columna, sentido), \n",
    "    donde sentido puede ser 'max' o 'min'.\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "\n",
    "    # Convertimos todo a \"maximizar\" (lo que sea 'min' lo multiplicamos por -1).\n",
    "    for col, sense in objectives:\n",
    "        if sense == 'min':\n",
    "            data[col] = -data[col]\n",
    "\n",
    "    is_dominated = np.zeros(len(data), dtype=bool)\n",
    "\n",
    "    # Revisamos si una fila i es dominada por otra fila j\n",
    "    for i in range(len(data)):\n",
    "        if is_dominated[i]:\n",
    "            continue  # Ya está marcada como dominada\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            better_or_equal_j = True\n",
    "            strictly_better_j = False\n",
    "\n",
    "            for col, _ in objectives:\n",
    "                if data.iloc[j][col] < data.iloc[i][col]:\n",
    "                    better_or_equal_j = False\n",
    "                    break\n",
    "                elif data.iloc[j][col] > data.iloc[i][col]:\n",
    "                    strictly_better_j = True\n",
    "\n",
    "            if better_or_equal_j and strictly_better_j:\n",
    "                is_dominated[i] = True\n",
    "                break\n",
    "\n",
    "    # Nos quedamos con las filas no dominadas\n",
    "    pareto_df = df.loc[~is_dominated].copy()\n",
    "    return pareto_df\n",
    "\n",
    "def main():\n",
    "    # 1. Cargamos el DataFrame\n",
    "    xml_file = \"/mnt/c/Users/Administrador/Downloads/ReportOptimizer-4842620.xml\"\n",
    "    df = parse_mt5_optimization_report(xml_file)\n",
    "    \n",
    "    # 2. Obtenemos el frente de Pareto (max Profit, max Sharpe, min Drawdown)\n",
    "    pf = pareto_frontier(df, [\n",
    "        (\"Profit\", \"max\"),\n",
    "        (\"Sharpe Ratio\", \"max\"),\n",
    "        (\"Equity DD %\", \"min\"),\n",
    "        (\"max_spread\", \"min\")\n",
    "    ])\n",
    "    print(f\"\\nSe encontraron {len(pf)} configuraciones en el frente de Pareto.\\n\")\n",
    "\n",
    "    print(pf[[\"Profit\", \"Sharpe Ratio\", \"Equity DD %\", \"max_orders\", \"orders_time_delay\",\n",
    "              \"max_spread\", \"stoploss\", \"takeprofit\"]].head(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arima best params searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def determine_arima_params(series, start_p=0, start_q=0, max_p=5, max_q=5, m=1, seasonal=False, stepwise=True, suppress_warnings=True, trace=False):\n",
    "    \"\"\"\n",
    "    Determina automáticamente los parámetros p, d, q para un modelo ARIMA dado una serie temporal.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): Serie temporal de datos.\n",
    "        start_p (int): Valor inicial de p para la búsqueda.\n",
    "        start_q (int): Valor inicial de q para la búsqueda.\n",
    "        max_p (int): Valor máximo de p para considerar.\n",
    "        max_q (int): Valor máximo de q para considerar.\n",
    "        m (int): Periodicidad para modelos estacionales. Por defecto es 1 (no estacional).\n",
    "        seasonal (bool): Si True, busca modelos SARIMA.\n",
    "        stepwise (bool): Si True, utiliza búsqueda stepwise para acelerar el proceso.\n",
    "        suppress_warnings (bool): Si True, suprime advertencias durante el ajuste.\n",
    "        trace (bool): Si True, imprime información detallada durante la búsqueda.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (p, d, q) óptimos para el modelo ARIMA.\n",
    "    \"\"\"\n",
    "    # Ajustar el modelo ARIMA automáticamente\n",
    "    model = pm.auto_arima(\n",
    "        series,\n",
    "        start_p=start_p,\n",
    "        start_q=start_q,\n",
    "        max_p=max_p,\n",
    "        max_q=max_q,\n",
    "        m=m,\n",
    "        seasonal=seasonal,\n",
    "        trace=trace,\n",
    "        error_action='ignore',\n",
    "        suppress_warnings=suppress_warnings,\n",
    "        stepwise=stepwise\n",
    "    )\n",
    "    \n",
    "    # Obtener los parámetros óptimos\n",
    "    p, d, q = model.order\n",
    "    \n",
    "    return p, d, q\n",
    "\n",
    "def analyze_arima_by_year(df):\n",
    "    \"\"\"\n",
    "    Divide el DataFrame por años y determina los valores p, d, q de ARIMA para cada año.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con una columna '<CLOSE>' y una columna de fecha.\n",
    "\n",
    "    Returns:\n",
    "        dict: Diccionario con los resultados por año.\n",
    "    \"\"\"\n",
    "    # Convertir la columna de fecha a datetime\n",
    "    df['<DATE>'] = pd.to_datetime(df['<DATE>'], infer_datetime_format=True)\n",
    "\n",
    "    # Agregar una columna con el año\n",
    "    df['Year'] = df['<DATE>'].dt.year\n",
    "\n",
    "    # Diccionario para almacenar los resultados por año\n",
    "    results = {}\n",
    "\n",
    "    for year, group in df.groupby('Year'):\n",
    "        print(f\"Procesando el año: {year}\")\n",
    "        series = group['<CLOSE>']\n",
    "        if len(series) > 10:  # Asegurar datos suficientes\n",
    "            p, d, q = determine_arima_params(series, trace=True)\n",
    "            results[year] = {'p': p, 'd': d, 'q': q}\n",
    "            print(f\"Año {year}: p={p}, d={d}, q={q}\")\n",
    "        else:\n",
    "            print(f\"Año {year}: No hay suficientes datos para ARIMA.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Ejemplo de uso:\n",
    "if __name__ == \"__main__\":\n",
    "    file_folder = r'/mnt/c/Users/Administrador/Downloads'\n",
    "    file_pattern = os.path.join(file_folder, 'GDAXI_*.csv')\n",
    "    df_file_path = glob.glob(file_pattern)\n",
    "    df = pd.read_csv(df_file_path[0], delimiter='\\t')\n",
    "    print(df.head(1))\n",
    "    print(df.tail(1))\n",
    "\n",
    "    # Obtener los resultados por año\n",
    "    results_by_year = analyze_arima_by_year(df)\n",
    "\n",
    "    # Imprimir los resultados finales\n",
    "    for year, params in results_by_year.items():\n",
    "        print(f\"Año {year}: p={params['p']}, d={params['d']}, q={params['q']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
