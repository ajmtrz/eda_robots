{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5302a1a",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.labeling_lib import get_labels_one_direction\n",
    "from modules.labeling_lib import sliding_window_clustering\n",
    "from modules.tester_lib import tester_one_direction\n",
    "from modules.export_lib import export_model_to_ONNX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cac365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener precios\n",
    "def get_prices(hyper_params) -> pd.DataFrame:\n",
    "    history_file = os.path.join(hyper_params[\"history_path\"], f\"{hyper_params['symbol']}_{hyper_params['timeframe']}.csv\")\n",
    "    p = pd.read_csv(history_file, sep=r\"\\s+\")\n",
    "    pFixed = pd.DataFrame(columns=['time', 'close'])\n",
    "    pFixed['time'] = p['<DATE>'] + ' ' + p['<TIME>']\n",
    "    pFixed['time'] = pd.to_datetime(pFixed['time'], format='mixed')\n",
    "    pFixed['close'] = p['<CLOSE>']\n",
    "    pFixed.set_index('time', inplace=True)\n",
    "    return pFixed.dropna()\n",
    "# IngenierÃ­a de caracterÃ­sticas\n",
    "@njit\n",
    "def compute_features(close, periods, periods_meta, stats):\n",
    "    n = len(close)\n",
    "    total_features = (len(periods) * len(stats)) + len(periods_meta)\n",
    "    features = np.full((n, total_features), np.nan)\n",
    "\n",
    "    def std_manual(x):\n",
    "        m = np.mean(x)\n",
    "        return np.sqrt(np.sum((x - m) ** 2) / (x.size - 1))\n",
    "\n",
    "    def skew_manual(x):\n",
    "        m = np.mean(x)\n",
    "        s = std_manual(x)\n",
    "        return np.mean(((x - m) / s) ** 3) if s != 0 else 0.0\n",
    "\n",
    "    def kurt_manual(x):\n",
    "        m = np.mean(x)\n",
    "        s = std_manual(x)\n",
    "        return np.mean(((x - m) / s) ** 4) - 3 if s != 0 else 0.0\n",
    "    \n",
    "    def zscore_manual(x):\n",
    "        m = np.mean(x)\n",
    "        s = std_manual(x)\n",
    "        return (x[0] - m) / s if s != 0 else 0.0\n",
    "    \n",
    "    def entropy_manual(x):\n",
    "        bins = 10\n",
    "        minv = np.min(x)\n",
    "        maxv = np.max(x)\n",
    "        width = (maxv - minv) / bins\n",
    "        if width == 0:\n",
    "            return 0.0\n",
    "        hist = np.zeros(bins)\n",
    "        for val in x:\n",
    "            idx = int((val - minv) / width)\n",
    "            if idx == bins:  # caso borde\n",
    "                idx -= 1\n",
    "            hist[idx] += 1\n",
    "        total = x.size\n",
    "        entropy = 0.0\n",
    "        for i in range(bins):\n",
    "            p = hist[i] / total\n",
    "            if p > 0:\n",
    "                entropy -= p * np.log(p)\n",
    "        return entropy\n",
    "\n",
    "    def slope_manual(x):\n",
    "        n = x.size\n",
    "        x_idx = np.arange(n)\n",
    "        x_mean = np.mean(x_idx)\n",
    "        y_mean = np.mean(x)\n",
    "        numerator = np.sum((x_idx - x_mean) * (x - y_mean))\n",
    "        denominator = np.sum((x_idx - x_mean) ** 2)\n",
    "        return numerator / denominator if denominator != 0 else 0.0\n",
    "\n",
    "    # Procesar perÃ­odos normales\n",
    "    col = 0\n",
    "    for win in periods:\n",
    "        for s in stats:\n",
    "            for i in range(win, n):\n",
    "                window = close[i - win:i][::-1]\n",
    "                if s == \"std\":\n",
    "                    features[i, col] = std_manual(window)\n",
    "                elif s == \"skew\":\n",
    "                    features[i, col] = skew_manual(window)\n",
    "                elif s == \"kurt\":\n",
    "                    features[i, col] = kurt_manual(window)\n",
    "                elif s == \"zscore\":\n",
    "                    features[i, col] = zscore_manual(window)\n",
    "                elif s == \"mean\":\n",
    "                    features[i, col] = np.mean(window)\n",
    "                elif s == \"range\":\n",
    "                    features[i, col] = np.max(window) - np.min(window)\n",
    "                elif s == \"median\":\n",
    "                    features[i, col] = np.median(window)\n",
    "                elif s == \"mad\":\n",
    "                    features[i, col] = np.mean(np.abs(window - np.mean(window)))\n",
    "                elif s == \"var\":\n",
    "                    features[i, col] = np.var(window)\n",
    "                elif s == \"entropy\":\n",
    "                    features[i, col] = entropy_manual(window)\n",
    "                elif s == \"slope\":\n",
    "                    features[i, col] = slope_manual(window)\n",
    "            col += 1  # Incrementar col despuÃ©s de procesar todas las filas para esta estadÃ­stica y ventana\n",
    "\n",
    "    # Procesar perÃ­odos meta\n",
    "    for win in periods_meta:\n",
    "        for i in range(win, n):\n",
    "            window = close[i - win:i][::-1]\n",
    "            features[i, col] = std_manual(window)\n",
    "        col += 1\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_features(data: pd.DataFrame, hp):\n",
    "    close = data['close'].values\n",
    "    index = data.index\n",
    "    periods = hp[\"periods\"]\n",
    "    periods_meta = hp[\"periods_meta\"]\n",
    "    stats = hp[\"stats\"]\n",
    "    if len(stats) == 0:\n",
    "        raise ValueError(\"La lista de estadÃ­sticas estÃ¡ vacÃ­a.\")\n",
    "    feats = compute_features(close, np.array(periods), np.array(periods_meta), stats)\n",
    "    if np.isnan(feats).all():\n",
    "        return pd.DataFrame(index=index)\n",
    "    # Nombres de columnas\n",
    "    colnames = []\n",
    "    for p in periods:\n",
    "        for s in stats:\n",
    "            colnames.extend([f\"{p}_{s}_feature\"])\n",
    "    for p in periods_meta:\n",
    "        colnames.extend([f\"{p}_std_meta_feature\"])\n",
    "    df = pd.DataFrame(feats, columns=colnames, index=index)\n",
    "    df[\"close\"] = data[\"close\"]\n",
    "    return df.dropna()\n",
    "    \n",
    "def test_model_one_direction(\n",
    "        dataset: pd.DataFrame,\n",
    "        result:  list,\n",
    "        forward: datetime,\n",
    "        backward: datetime,\n",
    "        markup:  float,\n",
    "        direction: str,\n",
    "        plt: bool = False):\n",
    "\n",
    "    pr_tst = dataset.copy()\n",
    "    X = pr_tst.drop(columns=['close'])\n",
    "    X_meta = X.loc[:,  X.columns.str.contains('meta_feature')]\n",
    "    X      = X.loc[:, ~X.columns.str.contains('meta_feature')]\n",
    "\n",
    "    pr_tst['labels']      = result[0].predict_proba(X)[:,1]\n",
    "    pr_tst['meta_labels'] = result[1].predict_proba(X_meta)[:,1]\n",
    "\n",
    "    # CorrecciÃ³n aquÃ­:\n",
    "    pr_tst[['labels', 'meta_labels']] = (pr_tst[['labels', 'meta_labels']] > 0.5).astype(float)\n",
    "\n",
    "    return tester_one_direction(pr_tst, forward, backward, markup, direction, plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15736753",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e880b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_final_models(clustered: pd.DataFrame,\n",
    "                     meta: pd.DataFrame,\n",
    "                     oos_data: pd.DataFrame,\n",
    "                     hp: Dict[str, Any]) -> Tuple[float, Any, Any]:\n",
    "    \"\"\"Entrena modelo principal + metaâ€‘modelo y evalÃºa en OOS.\n",
    "\n",
    "    Devuelve (R2, model, meta_model).\n",
    "    \"\"\"\n",
    "    # ---------- 1) main model ----------\n",
    "    X_main = clustered.drop(columns=['labels', *meta.columns[meta.columns.str.contains('_meta_feature')]])\n",
    "    y_main = clustered['labels'].astype('int16')\n",
    "\n",
    "    # ---------- 2) metaâ€‘model ----------\n",
    "    X_meta = meta.loc[:, meta.columns.str.contains('_meta_feature')]\n",
    "    y_meta = meta['clusters'].astype('int16')\n",
    "    # 3) Split aleatorio (70/30)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_main, y_main, train_size=0.7, shuffle=True)\n",
    "    train_X_m, test_X_m, train_y_m, test_y_m = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.7, shuffle=True)\n",
    "    # debug\n",
    "    # common_index = X_main.index[0]\n",
    "    # display(X_main.loc[[common_index]])\n",
    "    # display(X_meta.loc[[common_index]])\n",
    "    # 4) Hiperâ€‘parÃ¡metros CatBoost (con valores por defecto + overrides)\n",
    "    cat_main_params = dict(\n",
    "        iterations=hp.get('cat_main_iterations', 500),\n",
    "        depth=hp.get('cat_main_depth', 6),\n",
    "        learning_rate=hp.get('cat_main_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_main_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['Accuracy'],\n",
    "        eval_metric='Accuracy',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    model = CatBoostClassifier(**cat_main_params)\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), early_stopping_rounds=25)\n",
    "\n",
    "    cat_meta_params = dict(\n",
    "        iterations=hp.get('cat_meta_iterations', 500),\n",
    "        depth=hp.get('cat_meta_depth', 6),\n",
    "        learning_rate=hp.get('cat_meta_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_meta_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['F1'],\n",
    "        eval_metric='F1',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    meta_model = CatBoostClassifier(**cat_meta_params)\n",
    "    meta_model.fit(train_X_m, train_y_m, eval_set=(test_X_m, test_y_m), early_stopping_rounds=15)\n",
    "\n",
    "    # 5)Â EvaluaciÃ³n en datos fuera de muestra\n",
    "    R2 = test_model_one_direction(\n",
    "        oos_data,\n",
    "        [model, meta_model],\n",
    "        hp['full forward'],\n",
    "        hp['forward'],\n",
    "        hp['markup'],\n",
    "        hp['direction'],\n",
    "        plt=False,\n",
    "    )\n",
    "    if math.isnan(R2):\n",
    "        R2 = -1.0\n",
    "    return R2, model, meta_model\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#      â”€â”€â”€ FUNCIÃ“N OBJETIVO PARA OPTUNA â”€â”€â”€\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def objective(trial: optuna.trial.Trial, base_hp: Dict[str, Any], study=None) -> float:\n",
    "    hp = base_hp.copy()\n",
    "\n",
    "    # ÂµÂ·Â·Â· Espacio de bÃºsqueda Â·Â·Â·Âµ\n",
    "    hp['n_clusters']               = trial.suggest_int('n_clusters', 5, 60, step=5)\n",
    "    hp['window_size']              = trial.suggest_int('window_size', 100, 500, step=10)\n",
    "    hp['label_min']                = trial.suggest_int('label_min', 1, 5)\n",
    "    hp['label_max']                = trial.suggest_int('label_max', hp['label_min']+5, 30)\n",
    "    hp['markup']                   = trial.suggest_float(\"markup\", 0.05, 0.3)\n",
    "    # CatBoost (main)\n",
    "    hp['cat_main_iterations']      = trial.suggest_int('cat_main_iterations', 100, 1000, step=100)\n",
    "    hp['cat_main_depth']           = trial.suggest_int('cat_main_depth', 4, 10)\n",
    "    hp['cat_main_learning_rate']   = trial.suggest_float('cat_main_learning_rate', 0.01, 0.3, log=True)\n",
    "    hp['cat_main_l2_leaf_reg']     = trial.suggest_float('cat_main_l2_leaf_reg', 1.0, 7.0)\n",
    "    # CatBoost (meta)\n",
    "    hp['cat_meta_iterations']      = trial.suggest_int('cat_meta_iterations', 100, 500, step=100)\n",
    "    hp['cat_meta_depth']           = trial.suggest_int('cat_meta_depth', 4, 8)\n",
    "    hp['cat_meta_learning_rate']   = trial.suggest_float('cat_meta_learning_rate', 0.03, 0.2, log=True)\n",
    "    hp['cat_meta_l2_leaf_reg']     = trial.suggest_float('cat_meta_l2_leaf_reg', 1.0, 5.0)\n",
    "    \n",
    "    # ğŸ” PerÃ­odos aleatorios\n",
    "    # all_periods = list(range(5, 301, 5))\n",
    "    # random_period_candidates = sorted(random.sample(all_periods, k=trial.suggest_int(\"n_periods\", 5, 12)))\n",
    "    # hp['periods'] = [p for p in random_period_candidates if trial.suggest_categorical(f\"use_period_{p}\", [True, False])]\n",
    "    # if len(hp['periods']) == 0:\n",
    "    #     return -np.inf\n",
    "    \n",
    "    # ğŸ“Š SelecciÃ³n de estadÃ­sticas\n",
    "    stat_choices = [\"std\", \"skew\", \"kurt\", \"zscore\", \"mean\", \"range\", \"median\", \"mad\", \"var\", \"entropy\", \"slope\"]\n",
    "    selected_stats = [s for s in stat_choices if trial.suggest_categorical(f\"use_stat_{s}\", [True, False])]\n",
    "    if len(selected_stats) == 0:\n",
    "        return -np.inf\n",
    "    hp[\"stats\"] = selected_stats\n",
    "\n",
    "    # Dataset completo\n",
    "    full_ds = get_features(get_prices(hp), hp)\n",
    "    ds_train = full_ds[(full_ds.index > hp['backward']) & (full_ds.index < hp['forward'])]\n",
    "    ds_oos   = full_ds[(full_ds.index >= hp['forward']) & (full_ds.index < hp['full forward'])]\n",
    "    \n",
    "    # Clustering con ventana deslizante\n",
    "    data = sliding_window_clustering(\n",
    "        ds_train,\n",
    "        n_clusters=hp['n_clusters'],\n",
    "        window_size=hp['window_size']\n",
    "    )\n",
    "    \n",
    "    best_R2 = -math.inf\n",
    "    for clust in np.sort(data['clusters'].unique()):\n",
    "        clustered_data = data[data['clusters'] == clust].copy()\n",
    "        if len(clustered_data) < 500:\n",
    "            continue\n",
    "\n",
    "        clustered_data = get_labels_one_direction(\n",
    "            clustered_data,\n",
    "            markup    = hp['markup'],\n",
    "            min       = hp['label_min'],\n",
    "            max       = hp['label_max'],\n",
    "            direction = hp['direction'])\n",
    "\n",
    "        clustered_data = clustered_data.drop(['close', 'clusters'], axis=1)\n",
    "        meta_data = data.copy()\n",
    "        meta_data['clusters'] = (meta_data['clusters'] == clust).astype(int)\n",
    "\n",
    "        R2, model, meta_model = fit_final_models(\n",
    "            clustered_data,\n",
    "            meta_data.drop(['close'], axis=1),\n",
    "            ds_oos,\n",
    "            hp\n",
    "        )\n",
    "\n",
    "        if R2 < 1.0 and R2 > best_R2:\n",
    "            best_R2 = R2\n",
    "            best_pack = (model, meta_model)\n",
    "            \n",
    "            # Solo guardar si este R2 es mejor que cualquier guardado antes\n",
    "            if study is not None:\n",
    "                prev_best = study.user_attrs.get(\"best_r2\", -np.inf)\n",
    "                if best_R2 > prev_best:\n",
    "                    study.set_user_attr(\"best_model\", best_pack[0])\n",
    "                    study.set_user_attr(\"best_meta_model\", best_pack[1])\n",
    "                    study.set_user_attr(\"best_r2\", best_R2)\n",
    "                    study.set_user_attr(\"best_stats\", hp[\"stats\"])\n",
    "                    study.set_user_attr(\"best_periods\", hp[\"periods\"])\n",
    "                    study.set_user_attr(\"best_periods_meta\", hp[\"periods_meta\"])\n",
    "\n",
    "    return best_R2\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#                 â”€â”€â”€ PIPELINE DE OPTIMIZACIÃ“N + EXPORT â”€â”€â”€\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def optimize_and_export(symbol, timeframe, model_number, n_trials):\n",
    "    \"\"\"Lanza Optuna, guarda el mejor modelo y lo exporta a ONNX.\"\"\"\n",
    "\n",
    "    common_file_folder = r\"/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/Common/Files/\"\n",
    "    mql5_files_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/'\n",
    "    mql5_include_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Include/ajmtrz/include/Dmitrievsky'\n",
    "\n",
    "    base_hp: Dict[str, Any] = {\n",
    "        'symbol': symbol,\n",
    "        'timeframe': timeframe,\n",
    "        'models_export_path': mql5_files_folder,\n",
    "        'include_export_path': mql5_include_folder,\n",
    "        'history_path': common_file_folder,\n",
    "        'best_models': [],\n",
    "        'stats': [],\n",
    "        'model_number': model_number,\n",
    "        'markup': 0.20,\n",
    "        'label_min'  : 1,\n",
    "        'label_max'  : 15,\n",
    "        'direction': 'buy',\n",
    "        'n_clusters': 30,\n",
    "        'window_size': 350,\n",
    "        'periods': [i for i in range(5, 300, 30)],\n",
    "        'periods_meta': [5],\n",
    "        'backward': datetime(2020, 3, 26),\n",
    "        'forward': datetime(2024, 1, 1),\n",
    "        'full forward': datetime(2026, 1, 1),\n",
    "    }\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda t: objective(t, base_hp, study), n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "\n",
    "    print(\"\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
    "    print(\"â”‚      MEJOR RESULTADOÂ =Â {:.4f}                 â”‚\".format(study.best_value))\n",
    "    print(\"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n\")\n",
    "    print(\"ParÃ¡metros Ã³ptimos:\\n\", study.best_params)\n",
    "\n",
    "    # Recuperar el mejor modelo y metaâ€‘modelo\n",
    "    base_hp.update(study.best_params)\n",
    "    model      = study.user_attrs[\"best_model\"]\n",
    "    meta_model = study.user_attrs[\"best_meta_model\"]\n",
    "    best_r2    = study.user_attrs[\"best_r2\"]\n",
    "    base_hp['stats'] = study.user_attrs[\"best_stats\"]\n",
    "    base_hp['periods'] = study.user_attrs[\"best_periods\"]\n",
    "    base_hp['periods_meta'] = study.user_attrs[\"best_periods_meta\"]\n",
    "    base_hp.pop('best_models', None)\n",
    "    print(\"Exportando modelos ONNXâ€¦ R2 = {:.4f}\".format(best_r2))\n",
    "    export_model_to_ONNX(best_models=[model, meta_model], **base_hp)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = 'XAUUSD'\n",
    "    timeframe = 'H1'\n",
    "    n_trials_per_model = 50\n",
    "    model_range = range(20, 50)\n",
    "    for i in tqdm(model_range, desc=f\"Optimizando {symbol}/{timeframe}\", unit=\"modelo\"):\n",
    "        try:\n",
    "            optimize_and_export(symbol, timeframe, i, n_trials=n_trials_per_model)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"\\nError procesando modelo {i}: {e}\") # tqdm.write evita romper la barra\n",
    "            continue\n",
    "    print(\"Proceso de optimizaciÃ³n completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
