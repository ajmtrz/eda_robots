{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5302a1a",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed4c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.labeling_lib import get_labels_one_direction\n",
    "from modules.labeling_lib import sliding_window_clustering\n",
    "from modules.tester_lib import tester_one_direction\n",
    "from modules.export_lib import export_model_to_ONNX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73cac365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener precios\n",
    "def get_prices(hyper_params) -> pd.DataFrame:\n",
    "    history_file = os.path.join(hyper_params[\"history_path\"], f\"{hyper_params['symbol']}_{hyper_params['timeframe']}.csv\")\n",
    "    p = pd.read_csv(history_file, sep=r\"\\s+\")\n",
    "    pFixed = pd.DataFrame(columns=['time', 'close'])\n",
    "    pFixed['time'] = p['<DATE>'] + ' ' + p['<TIME>']\n",
    "    pFixed['time'] = pd.to_datetime(pFixed['time'], format='mixed')\n",
    "    pFixed['close'] = p['<CLOSE>']\n",
    "    pFixed.set_index('time', inplace=True)\n",
    "    return pFixed.dropna()\n",
    "# Ingeniería de características\n",
    "@njit\n",
    "def compute_features(close, periods, periods_meta, stats):\n",
    "    n = len(close)\n",
    "    total_features = (len(periods) * len(stats)) + len(periods_meta)\n",
    "    features = np.full((n, total_features), np.nan)\n",
    "\n",
    "    def std_manual(x):\n",
    "        m = np.mean(x)\n",
    "        return np.sqrt(np.sum((x - m) ** 2) / (x.size - 1))\n",
    "\n",
    "    def skew_manual(x):\n",
    "        m = np.mean(x)\n",
    "        s = std_manual(x)\n",
    "        return np.mean(((x - m) / s) ** 3) if s != 0 else 0.0\n",
    "\n",
    "    def kurt_manual(x):\n",
    "        m = np.mean(x)\n",
    "        s = std_manual(x)\n",
    "        return np.mean(((x - m) / s) ** 4) - 3 if s != 0 else 0.0\n",
    "    \n",
    "    def zscore_manual(x):\n",
    "        m = np.mean(x)\n",
    "        s = std_manual(x)\n",
    "        return (x[0] - m) / s if s != 0 else 0.0\n",
    "    \n",
    "    def entropy_manual(x):\n",
    "        bins = 10\n",
    "        minv = np.min(x)\n",
    "        maxv = np.max(x)\n",
    "        width = (maxv - minv) / bins\n",
    "        if width == 0:\n",
    "            return 0.0\n",
    "        hist = np.zeros(bins)\n",
    "        for val in x:\n",
    "            idx = int((val - minv) / width)\n",
    "            if idx == bins:  # caso borde\n",
    "                idx -= 1\n",
    "            hist[idx] += 1\n",
    "        total = x.size\n",
    "        entropy = 0.0\n",
    "        for i in range(bins):\n",
    "            p = hist[i] / total\n",
    "            if p > 0:\n",
    "                entropy -= p * np.log(p)\n",
    "        return entropy\n",
    "\n",
    "    def slope_manual(x):\n",
    "        n = x.size\n",
    "        x_idx = np.ascontiguousarray(np.arange(n))\n",
    "        x_mean = np.mean(x_idx)\n",
    "        y_mean = np.mean(x)\n",
    "        numerator = np.sum((x_idx - x_mean) * (x - y_mean))\n",
    "        denominator = np.sum((x_idx - x_mean) ** 2)\n",
    "        return numerator / denominator if denominator != 0 else 0.0\n",
    "\n",
    "    def momentum_manual(x):\n",
    "        return (x[0] / x[-1]) - 1.0 if x[-1] != 0 else 0.0\n",
    "    \n",
    "    def roc_manual(x):\n",
    "        n = len(x)\n",
    "        if n < 2:\n",
    "            return 0.0\n",
    "        return ((x[0] - x[-1]) / x[-1]) * 100 if x[-1] != 0 else 0.0\n",
    "    \n",
    "    def fractal_dimension_manual(x):\n",
    "        # Método de box-counting simplificado\n",
    "        x = np.ascontiguousarray(x)  # Asegurar array contiguo\n",
    "        eps = np.std(x) / 4  # epsilon como fracción de std\n",
    "        if eps == 0:  # Evitar división por cero\n",
    "            return 1.0\n",
    "        count = np.sum(np.abs(np.diff(x)) > eps)\n",
    "        if count == 0:\n",
    "            return 1.0\n",
    "        return 1.0 + np.log(count) / np.log(len(x))\n",
    "    \n",
    "    def hurst_manual(x):\n",
    "        # Exponente de Hurst simplificado\n",
    "        n = len(x)\n",
    "        if n < 4:\n",
    "            return 0.5\n",
    "        lags = min(n-1, 20)  # usar máximo 20 lags\n",
    "        tau = np.ascontiguousarray(np.arange(1, lags+1))\n",
    "        rs = np.zeros(lags)\n",
    "        \n",
    "        for lag in range(1, lags+1):\n",
    "            roll_mean = np.mean(x[:n-lag+1])\n",
    "            roll_std = std_manual(x[:n-lag+1])\n",
    "            if roll_std == 0:\n",
    "                continue\n",
    "            rs[lag-1] = np.max(x[:n-lag+1]) / roll_std\n",
    "        \n",
    "        valid_rs = rs[rs != 0]\n",
    "        if len(valid_rs) < 2:\n",
    "            return 0.5\n",
    "        \n",
    "        return np.mean(np.log(valid_rs)) / np.log(n) if n > 1 else 0.5\n",
    "\n",
    "    # Procesar períodos normales\n",
    "    col = 0\n",
    "    for win in periods:\n",
    "        for s in stats:\n",
    "            for i in range(win, n):\n",
    "                window = close[i - win:i][::-1]\n",
    "                if s == \"std\":\n",
    "                    features[i, col] = std_manual(window)\n",
    "                elif s == \"skew\":\n",
    "                    features[i, col] = skew_manual(window)\n",
    "                elif s == \"kurt\":\n",
    "                    features[i, col] = kurt_manual(window)\n",
    "                elif s == \"zscore\":\n",
    "                    features[i, col] = zscore_manual(window)\n",
    "                elif s == \"mean\":\n",
    "                    features[i, col] = np.mean(window)\n",
    "                elif s == \"range\":\n",
    "                    features[i, col] = np.max(window) - np.min(window)\n",
    "                elif s == \"median\":\n",
    "                    features[i, col] = np.median(window)\n",
    "                elif s == \"mad\":\n",
    "                    features[i, col] = np.mean(np.abs(window - np.mean(window)))\n",
    "                elif s == \"var\":\n",
    "                    features[i, col] = np.var(window)\n",
    "                elif s == \"entropy\":\n",
    "                    features[i, col] = entropy_manual(window)\n",
    "                elif s == \"slope\":\n",
    "                    features[i, col] = slope_manual(window)\n",
    "                elif s == \"momentum\":\n",
    "                    features[i, col] = momentum_manual(window)\n",
    "                elif s == \"roc\":\n",
    "                    features[i, col] = roc_manual(window)\n",
    "                elif s == \"fractal\":\n",
    "                    features[i, col] = fractal_dimension_manual(window)\n",
    "                elif s == \"hurst\":\n",
    "                    features[i, col] = hurst_manual(window)\n",
    "            col += 1  # Incrementar col después de procesar todas las filas para esta estadística y ventana\n",
    "\n",
    "    # Procesar períodos meta\n",
    "    for win in periods_meta:\n",
    "        for i in range(win, n):\n",
    "            window = close[i - win:i][::-1]\n",
    "            features[i, col] = std_manual(window)\n",
    "        col += 1\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_features(data: pd.DataFrame, hp):\n",
    "    close = data['close'].values\n",
    "    index = data.index\n",
    "    periods = hp[\"periods\"]\n",
    "    periods_meta = hp[\"periods_meta\"]\n",
    "    stats = hp[\"stats\"]\n",
    "    if len(stats) == 0:\n",
    "        raise ValueError(\"La lista de estadísticas está vacía.\")\n",
    "    # Asegurar que los arrays sean contiguos\n",
    "    close = np.ascontiguousarray(close)\n",
    "    periods = np.ascontiguousarray(periods)\n",
    "    periods_meta = np.ascontiguousarray(periods_meta)\n",
    "    feats = compute_features(close, periods, periods_meta, stats)\n",
    "    if np.isnan(feats).all():\n",
    "        return pd.DataFrame(index=index)\n",
    "    # Nombres de columnas\n",
    "    colnames = []\n",
    "    for p in periods:\n",
    "        for s in stats:\n",
    "            colnames.extend([f\"{p}_{s}_feature\"])\n",
    "    for p in periods_meta:\n",
    "        colnames.extend([f\"{p}_std_meta_feature\"])\n",
    "    df = pd.DataFrame(feats, columns=colnames, index=index)\n",
    "    df[\"close\"] = data[\"close\"]\n",
    "    return df.dropna()\n",
    "    \n",
    "def test_model_one_direction(\n",
    "        dataset: pd.DataFrame,\n",
    "        result:  list,\n",
    "        forward: datetime,\n",
    "        backward: datetime,\n",
    "        markup:  float,\n",
    "        direction: str,\n",
    "        plt: bool = False):\n",
    "\n",
    "    pr_tst = dataset.copy()\n",
    "    X = pr_tst.drop(columns=['close'])\n",
    "    X_meta = X.loc[:,  X.columns.str.contains('meta_feature')]\n",
    "    X      = X.loc[:, ~X.columns.str.contains('meta_feature')]\n",
    "\n",
    "    pr_tst['labels']      = result[0].predict_proba(X)[:,1]\n",
    "    pr_tst['meta_labels'] = result[1].predict_proba(X_meta)[:,1]\n",
    "\n",
    "    # Corrección aquí:\n",
    "    pr_tst[['labels', 'meta_labels']] = (pr_tst[['labels', 'meta_labels']] > 0.5).astype(float)\n",
    "\n",
    "    return tester_one_direction(pr_tst, forward, backward, markup, direction, plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15736753",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e880b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizando XAUUSD/H1: 100%|██████████| 1/1 [00:10<00:00, 10.84s/modelo]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "┌───────────────────────────────────────────────┐\n",
      "│      MEJOR RESULTADO = 2.1900                 │\n",
      "└───────────────────────────────────────────────┘\n",
      "\n",
      "Parámetros óptimos:\n",
      " {'n_clusters': 30, 'window_size': 700, 'label_min': 2, 'label_max': 18, 'markup': 0.21490689395601428, 'cat_main_iterations': 800, 'cat_main_depth': 10, 'cat_main_learning_rate': 0.010399841441761907, 'cat_main_l2_leaf_reg': 5.708021659059657, 'cat_meta_iterations': 200, 'cat_meta_depth': 8, 'cat_meta_learning_rate': 0.2052901480911591, 'cat_meta_l2_leaf_reg': 0.896674438708679, 'n_periods_main': 6, 'period_main_0': 22, 'period_main_1': 98, 'period_main_2': 129, 'period_main_3': 11, 'period_main_4': 3, 'period_main_5': 199, 'n_periods_meta': 2, 'period_meta_0': 3, 'period_meta_1': 4, 'stat_weight_std': 0.7178274533239766, 'stat_weight_skew': 0.16556769161617357, 'stat_weight_kurt': 0.2979526331352256, 'stat_weight_zscore': 0.1431887083041441, 'stat_weight_mean': 0.11784705942036189, 'stat_weight_range': 0.543165119030677, 'stat_weight_median': 0.8928493703524973, 'stat_weight_mad': 0.2811920472199603, 'stat_weight_var': 0.9002081171047327, 'stat_weight_entropy': 0.35960667850422046, 'stat_weight_slope': 0.6134889007363353, 'stat_weight_momentum': 0.6957127503004555, 'stat_weight_roc': 0.2927235347269185, 'stat_weight_fractal': 0.2863428319904966, 'stat_weight_hurst': 0.4230415030372172}\n",
      "Exportando modelos ONNX… R2 = 2.1900\n",
      "Modelo /mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/dmitrievsky_model_XAUUSD_H1_0.onnx ONNX exportado correctamente\n",
      "Modelo /mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/dmitrievsky_model_m_XAUUSD_H1_0.onnx ONNX exportado correctamente\n",
      "The file /mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Include/ajmtrz/include/Dmitrievsky/XAUUSD_H1_ONNX_include_0.mqh has been written to disk\n",
      "Proceso de optimización completado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_final_models(clustered: pd.DataFrame,\n",
    "                     meta: pd.DataFrame,\n",
    "                     oos_data: pd.DataFrame,\n",
    "                     hp: Dict[str, Any]) -> Tuple[float, Any, Any]:\n",
    "    \"\"\"Entrena modelo principal + meta‑modelo y evalúa en OOS.\n",
    "\n",
    "    Devuelve (R2, model, meta_model).\n",
    "    \"\"\"\n",
    "    # ---------- 1) main model ----------\n",
    "    X_main = clustered.drop(columns=['labels', *meta.columns[meta.columns.str.contains('_meta_feature')]])\n",
    "    y_main = clustered['labels'].astype('int16')\n",
    "\n",
    "    # ---------- 2) meta‑model ----------\n",
    "    X_meta = meta.loc[:, meta.columns.str.contains('_meta_feature')]\n",
    "    y_meta = meta['clusters'].astype('int16')\n",
    "    # 3) Split aleatorio (70/30)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_main, y_main, train_size=0.7, shuffle=True)\n",
    "    train_X_m, test_X_m, train_y_m, test_y_m = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.7, shuffle=True)\n",
    "    # debug\n",
    "    # common_index = X_main.index[0]\n",
    "    # display(X_main.loc[[common_index]])\n",
    "    # display(X_meta.loc[[common_index]])\n",
    "    # 4) Hiper‑parámetros CatBoost (con valores por defecto + overrides)\n",
    "    cat_main_params = dict(\n",
    "        iterations=hp.get('cat_main_iterations', 500),\n",
    "        depth=hp.get('cat_main_depth', 6),\n",
    "        learning_rate=hp.get('cat_main_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_main_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['Accuracy'],\n",
    "        eval_metric='Accuracy',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    model = CatBoostClassifier(**cat_main_params)\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), early_stopping_rounds=25)\n",
    "\n",
    "    cat_meta_params = dict(\n",
    "        iterations=hp.get('cat_meta_iterations', 500),\n",
    "        depth=hp.get('cat_meta_depth', 6),\n",
    "        learning_rate=hp.get('cat_meta_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_meta_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['F1'],\n",
    "        eval_metric='F1',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    meta_model = CatBoostClassifier(**cat_meta_params)\n",
    "    meta_model.fit(train_X_m, train_y_m, eval_set=(test_X_m, test_y_m), early_stopping_rounds=15)\n",
    "\n",
    "    # 5) Evaluación en datos fuera de muestra\n",
    "    R2 = test_model_one_direction(\n",
    "        oos_data,\n",
    "        [model, meta_model],\n",
    "        hp['full forward'],\n",
    "        hp['forward'],\n",
    "        hp['markup'],\n",
    "        hp['direction'],\n",
    "        plt=False,\n",
    "    )\n",
    "    if math.isnan(R2):\n",
    "        R2 = -1.0\n",
    "    return R2, model, meta_model\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#      ─── FUNCIÓN OBJETIVO PARA OPTUNA ───\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def objective(trial: optuna.trial.Trial, base_hp: Dict[str, Any], study=None) -> float:\n",
    "    hp = base_hp.copy()\n",
    "\n",
    "    # µ··· Espacio de búsqueda optimizado ···µ\n",
    "    # Parámetros de clustering más amplios para encontrar patrones más diversos\n",
    "    hp['n_clusters'] = trial.suggest_int('n_clusters', 10, 100, step=10)  \n",
    "    hp['window_size'] = trial.suggest_int('window_size', 200, 800, step=50)\n",
    "    \n",
    "    # Parámetros de etiquetado más agresivos\n",
    "    hp['label_min'] = trial.suggest_int('label_min', 2, 8)\n",
    "    hp['label_max'] = trial.suggest_int('label_max', hp['label_min']+8, 40)\n",
    "    hp['markup'] = trial.suggest_float(\"markup\", 0.1, 0.4)\n",
    "\n",
    "    # CatBoost principal - Mayor capacidad de aprendizaje\n",
    "    hp['cat_main_iterations'] = trial.suggest_int('cat_main_iterations', 300, 2000, step=100)\n",
    "    hp['cat_main_depth'] = trial.suggest_int('cat_main_depth', 6, 12)\n",
    "    hp['cat_main_learning_rate'] = trial.suggest_float('cat_main_learning_rate', 0.005, 0.4, log=True)\n",
    "    hp['cat_main_l2_leaf_reg'] = trial.suggest_float('cat_main_l2_leaf_reg', 0.5, 10.0)\n",
    "\n",
    "    # CatBoost meta - Enfoque en precisión\n",
    "    hp['cat_meta_iterations'] = trial.suggest_int('cat_meta_iterations', 200, 1000, step=100)\n",
    "    hp['cat_meta_depth'] = trial.suggest_int('cat_meta_depth', 5, 10)\n",
    "    hp['cat_meta_learning_rate'] = trial.suggest_float('cat_meta_learning_rate', 0.01, 0.3, log=True)\n",
    "    hp['cat_meta_l2_leaf_reg'] = trial.suggest_float('cat_meta_l2_leaf_reg', 0.5, 8.0)\n",
    "\n",
    "    # Optimización de períodos para el modelo principal\n",
    "    n_periods_main = trial.suggest_int('n_periods_main', 5, 15)\n",
    "    main_periods = []\n",
    "    for i in range(n_periods_main):\n",
    "        period = trial.suggest_int(f'period_main_{i}', 2, 200, log=True)\n",
    "        main_periods.append(period)\n",
    "    main_periods = sorted(list(set(main_periods)))  # Eliminar duplicados y ordenar\n",
    "    if len(main_periods) < 3:  # Asegurar mínimo de períodos\n",
    "        return -np.inf\n",
    "    hp['periods'] = main_periods\n",
    "\n",
    "    # Optimización de períodos para el meta-modelo\n",
    "    n_periods_meta = 1 #trial.suggest_int('n_periods_meta', 1, 2)\n",
    "    meta_periods = []\n",
    "    for i in range(n_periods_meta):\n",
    "        period = trial.suggest_int(f'period_meta_{i}', 2, 5)\n",
    "        meta_periods.append(period)\n",
    "    meta_periods = sorted(list(set(meta_periods)))  # Eliminar duplicados y ordenar\n",
    "    hp['periods_meta'] = meta_periods\n",
    "\n",
    "    # Selección de estadísticas con pesos\n",
    "    stat_choices = {\n",
    "        \"std\": 0.8,\n",
    "        \"skew\": 0.6, \n",
    "        \"kurt\": 0.5,\n",
    "        \"zscore\": 0.9,\n",
    "        \"mean\": 0.7,\n",
    "        \"range\": 0.8,\n",
    "        \"median\": 0.6,\n",
    "        \"mad\": 0.5,\n",
    "        \"var\": 0.7,\n",
    "        \"entropy\": 0.4,\n",
    "        \"slope\": 0.9,\n",
    "        \"momentum\": 0.8,\n",
    "        \"roc\": 0.7,\n",
    "        \"fractal\": 0.6,\n",
    "        \"hurst\": 0.5\n",
    "    }\n",
    "    \n",
    "    selected_stats = []\n",
    "    for stat, weight in stat_choices.items():\n",
    "        if trial.suggest_float(f\"stat_weight_{stat}\", 0, 1) > (1 - weight):\n",
    "            selected_stats.append(stat)\n",
    "            \n",
    "    if len(selected_stats) < 3:  # Asegurar mínimo de features\n",
    "        return -np.inf\n",
    "    hp[\"stats\"] = selected_stats\n",
    "\n",
    "    # Dataset completo\n",
    "    full_ds = get_features(get_prices(hp), hp)\n",
    "    ds_train = full_ds[(full_ds.index > hp['backward']) & (full_ds.index < hp['forward'])]\n",
    "    ds_oos = full_ds[(full_ds.index >= hp['forward']) & (full_ds.index < hp['full forward'])]\n",
    "    \n",
    "    # Clustering con ventana deslizante\n",
    "    data = sliding_window_clustering(\n",
    "        ds_train,\n",
    "        n_clusters=hp['n_clusters'],\n",
    "        window_size=hp['window_size']\n",
    "    )\n",
    "    \n",
    "    best_R2 = -math.inf\n",
    "    valid_clusters = 0\n",
    "    \n",
    "    # Evaluar clusters ordenados por tamaño\n",
    "    cluster_sizes = data['clusters'].value_counts()\n",
    "    for clust in cluster_sizes.index:\n",
    "        clustered_data = data[data['clusters'] == clust].copy()\n",
    "        if len(clustered_data) < 750:  # Aumentar mínimo de muestras\n",
    "            continue\n",
    "            \n",
    "        valid_clusters += 1\n",
    "        clustered_data = get_labels_one_direction(\n",
    "            clustered_data,\n",
    "            markup=hp['markup'],\n",
    "            min=hp['label_min'],\n",
    "            max=hp['label_max'],\n",
    "            direction=hp['direction'])\n",
    "\n",
    "        clustered_data = clustered_data.drop(['close', 'clusters'], axis=1)\n",
    "        meta_data = data.copy()\n",
    "        meta_data['clusters'] = (meta_data['clusters'] == clust).astype(int)\n",
    "\n",
    "        R2, model, meta_model = fit_final_models(\n",
    "            clustered_data,\n",
    "            meta_data.drop(['close'], axis=1),\n",
    "            ds_oos,\n",
    "            hp\n",
    "        )\n",
    "\n",
    "        if R2 > best_R2:\n",
    "            best_R2 = R2\n",
    "            best_pack = (model, meta_model)\n",
    "            \n",
    "            if study is not None:\n",
    "                prev_best = study.user_attrs.get(\"best_r2\", -np.inf)\n",
    "                if best_R2 > prev_best:\n",
    "                    study.set_user_attr(\"best_model\", best_pack[0])\n",
    "                    study.set_user_attr(\"best_meta_model\", best_pack[1])\n",
    "                    study.set_user_attr(\"best_r2\", best_R2)\n",
    "                    study.set_user_attr(\"best_stats\", hp[\"stats\"])\n",
    "                    study.set_user_attr(\"best_periods\", hp[\"periods\"])\n",
    "                    study.set_user_attr(\"best_periods_meta\", hp[\"periods_meta\"])\n",
    "                    \n",
    "    # Penalizar si muy pocos clusters válidos\n",
    "    if valid_clusters < 3:\n",
    "        best_R2 *= 0.5\n",
    "\n",
    "    return best_R2\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#                 ─── PIPELINE DE OPTIMIZACIÓN + EXPORT ───\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def optimize_and_export(symbol, timeframe, model_number, n_trials):\n",
    "    \"\"\"Lanza Optuna, guarda el mejor modelo y lo exporta a ONNX.\"\"\"\n",
    "\n",
    "    common_file_folder = r\"/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/Common/Files/\"\n",
    "    mql5_files_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/'\n",
    "    mql5_include_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Include/ajmtrz/include/Dmitrievsky'\n",
    "\n",
    "    base_hp: Dict[str, Any] = {\n",
    "        'symbol': symbol,\n",
    "        'timeframe': timeframe,\n",
    "        'models_export_path': mql5_files_folder,\n",
    "        'include_export_path': mql5_include_folder,\n",
    "        'history_path': common_file_folder,\n",
    "        'best_models': [],\n",
    "        'stats': [],\n",
    "        'model_number': model_number,\n",
    "        'markup': 0.20,\n",
    "        'label_min'  : 1,\n",
    "        'label_max'  : 15,\n",
    "        'direction': 'buy',\n",
    "        'n_clusters': 30,\n",
    "        'window_size': 350,\n",
    "        'periods': [i for i in range(5, 300, 30)],\n",
    "        'periods_meta': [5],\n",
    "        'backward': datetime(2020, 3, 26),\n",
    "        'forward': datetime(2024, 1, 1),\n",
    "        'full forward': datetime(2026, 1, 1),\n",
    "    }\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda t: objective(t, base_hp, study), n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "\n",
    "    print(\"\\n┌───────────────────────────────────────────────┐\")\n",
    "    print(\"│      MEJOR RESULTADO = {:.4f}                 │\".format(study.best_value))\n",
    "    print(\"└───────────────────────────────────────────────┘\\n\")\n",
    "    print(\"Parámetros óptimos:\\n\", study.best_params)\n",
    "\n",
    "    # Recuperar el mejor modelo y meta‑modelo\n",
    "    base_hp.update(study.best_params)\n",
    "    model      = study.user_attrs[\"best_model\"]\n",
    "    meta_model = study.user_attrs[\"best_meta_model\"]\n",
    "    best_r2    = study.user_attrs[\"best_r2\"]\n",
    "    base_hp['stats'] = study.user_attrs[\"best_stats\"]\n",
    "    base_hp['periods'] = study.user_attrs[\"best_periods\"]\n",
    "    base_hp['periods_meta'] = study.user_attrs[\"best_periods_meta\"]\n",
    "    base_hp.pop('best_models', None)\n",
    "    print(\"Exportando modelos ONNX… R2 = {:.4f}\".format(best_r2))\n",
    "    export_model_to_ONNX(best_models=[model, meta_model], **base_hp)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = 'XAUUSD'\n",
    "    timeframe = 'H1'\n",
    "    n_trials_per_model = 1\n",
    "    model_range = range(0, 1)\n",
    "    for i in tqdm(model_range, desc=f\"Optimizando {symbol}/{timeframe}\", unit=\"modelo\"):\n",
    "        try:\n",
    "            optimize_and_export(symbol, timeframe, i, n_trials=n_trials_per_model)\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"\\nError procesando modelo {i}: {e}\") # tqdm.write evita romper la barra\n",
    "            continue\n",
    "    print(\"Proceso de optimización completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
