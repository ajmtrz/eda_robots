{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15736753",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e880b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, Tuple\n",
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner, HyperbandPruner\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.labeling_lib import get_prices\n",
    "from modules.labeling_lib import get_features\n",
    "from modules.labeling_lib import get_labels_one_direction\n",
    "from modules.labeling_lib import sliding_window_clustering\n",
    "from modules.tester_lib import test_model_one_direction_clustering\n",
    "from modules.export_lib import export_model_to_ONNX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def fit_final_models(clustered: pd.DataFrame,\n",
    "                     meta: pd.DataFrame,\n",
    "                     oos_data: pd.DataFrame,\n",
    "                     backward_data: pd.DataFrame,\n",
    "                     hp: Dict[str, Any]) -> Tuple[float, float, Any, Any]:\n",
    "    \"\"\"\n",
    "    Entrena modelo principal + meta‑modelo y evalúa en OOS y backward.\n",
    "\n",
    "    Devuelve (R2_forward, R2_backward, model_main, meta_model).\n",
    "    \"\"\"\n",
    "    # ---------- 1) main model_main ----------\n",
    "    X_main = clustered.loc[:, ~clustered.columns.isin(['labels'] + list(meta.columns[meta.columns.str.contains('_meta_feature')]))]\n",
    "    y_main = clustered['labels'].astype('int16')\n",
    "\n",
    "    # ---------- 2) meta‑modelo ----------\n",
    "    X_meta = meta.loc[:, meta.columns.str.contains('_meta_feature')]\n",
    "    y_meta = meta['clusters'].astype('int16')\n",
    "    \n",
    "    # 3) Split aleatorio (70/30)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_main, y_main, train_size=0.7, shuffle=True, )\n",
    "    train_X_m, test_X_m, train_y_m, test_y_m = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.7, shuffle=True)\n",
    "\n",
    "    # 4) Hiper‑parámetros CatBoost (con valores por defecto + overrides)\n",
    "    cat_main_params = dict(\n",
    "        iterations=hp.get('cat_main_iterations', 500),\n",
    "        depth=hp.get('cat_main_depth', 6),\n",
    "        learning_rate=hp.get('cat_main_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_main_l2_leaf_reg', 3.0),\n",
    "        early_stopping_rounds=hp.get('cat_main_early_stopping'),\n",
    "        #rsm=hp.get('cat_main_rsm', 0.5),\n",
    "        custom_loss=['Accuracy'],\n",
    "        eval_metric='Accuracy',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    model_main = CatBoostClassifier(**cat_main_params)\n",
    "    model_main.fit(train_X, train_y, eval_set=(test_X, test_y))\n",
    "\n",
    "    cat_meta_params = dict(\n",
    "        iterations=hp.get('cat_meta_iterations', 500),\n",
    "        depth=hp.get('cat_meta_depth', 6),\n",
    "        learning_rate=hp.get('cat_meta_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_meta_l2_leaf_reg', 3.0),\n",
    "        early_stopping_rounds=hp.get('cat_meta_early_stopping'),\n",
    "        custom_loss=['F1'],\n",
    "        eval_metric='F1',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    meta_model = CatBoostClassifier(**cat_meta_params)\n",
    "    meta_model.fit(train_X_m, train_y_m, eval_set=(test_X_m, test_y_m))\n",
    "\n",
    "    # 5) Evaluación en datos fuera de muestra (forward)\n",
    "    R2_forward = test_model_one_direction_clustering(\n",
    "        oos_data,\n",
    "        [model_main, meta_model],\n",
    "        hp['full_forward'],\n",
    "        hp['forward'],\n",
    "        hp['markup'],\n",
    "        hp['direction'],\n",
    "        plt=False,\n",
    "    )\n",
    "    \n",
    "    # 6) Evaluación en datos históricos (backward)\n",
    "    R2_backward = test_model_one_direction_clustering(\n",
    "        backward_data,\n",
    "        [model_main, meta_model],\n",
    "        hp['forward'],\n",
    "        hp['backward'],\n",
    "        hp['markup'],\n",
    "        hp['direction'],\n",
    "        plt=False,\n",
    "    )\n",
    "    \n",
    "    # Validación menos estricta de scores mínimos\n",
    "    if R2_forward == -1.0 or R2_backward == -1.0:\n",
    "        return -10.0, -10.0, model_main, meta_model\n",
    "        \n",
    "    return R2_forward, R2_backward, model_main, meta_model\n",
    "\n",
    "def objective(trial: optuna.trial.Trial, base_hp: Dict[str, Any], study=None) -> float:\n",
    "    # ─── cálculo combinado simple y simétrico ──────────────────────────\n",
    "    def calc_score(fwd: float, bwd: float, eps: float = 1e-9) -> float:\n",
    "        if (fwd is None or bwd is None or\n",
    "            not np.isfinite(fwd) or not np.isfinite(bwd) or\n",
    "            fwd <= 0 or bwd <= 0):\n",
    "            return -1.0\n",
    "        mean   = 0.5 * (fwd + bwd)\n",
    "        delta  = abs(fwd - bwd) / max(abs(fwd), abs(bwd), eps)\n",
    "        score  = mean * (1.0 - delta)\n",
    "        return score\n",
    "\n",
    "    hp = {k: copy.deepcopy(v) for k, v in base_hp.items() if k != 'base_df'}\n",
    "    gc.collect()\n",
    "    # µ··· Espacio de búsqueda optimizado ···µ\n",
    "    # Parámetros de clustering más amplios para encontrar patrones más diversos\n",
    "    hp['n_clusters'] = trial.suggest_int('n_clusters', 5, 50, step=5)  \n",
    "    hp['window_size'] = trial.suggest_int('window_size', 50, 500, step=10)\n",
    "    hp['vol_period'] = trial.suggest_int('vol_period', 5, 50, step=5)\n",
    "    \n",
    "    # Parámetros de etiquetado más agresivos\n",
    "    hp['label_min'] = trial.suggest_int('label_min', 1, 5)\n",
    "    hp['label_max'] = trial.suggest_int('label_max', hp['label_min']+5, 30)\n",
    "    hp['markup'] = trial.suggest_float(\"markup\", 0.1, 0.4)\n",
    "\n",
    "    # CatBoost principal - Mayor capacidad de aprendizaje\n",
    "    hp['cat_main_iterations'] = trial.suggest_int('cat_main_iterations', 300, 2000, step=100)\n",
    "    hp['cat_main_depth'] = trial.suggest_int('cat_main_depth', 6, 12)\n",
    "    hp['cat_main_learning_rate'] = trial.suggest_float('cat_main_learning_rate', 0.005, 0.4, log=True)\n",
    "    hp['cat_main_l2_leaf_reg'] = trial.suggest_float('cat_main_l2_leaf_reg', 0.5, 10.0)\n",
    "    hp['cat_main_early_stopping'] = trial.suggest_int('cat_main_early_stopping', 10, 50, step=10)\n",
    "    #hp['cat_main_rsm'] = trial.suggest_float('cat_main_rsm', 0.1, 1.0)\n",
    "\n",
    "    # CatBoost meta - Enfoque en precisión\n",
    "    hp['cat_meta_iterations'] = trial.suggest_int('cat_meta_iterations', 200, 1000, step=100)\n",
    "    hp['cat_meta_depth'] = trial.suggest_int('cat_meta_depth', 5, 10)\n",
    "    hp['cat_meta_learning_rate'] = trial.suggest_float('cat_meta_learning_rate', 0.01, 0.3, log=True)\n",
    "    hp['cat_meta_l2_leaf_reg'] = trial.suggest_float('cat_meta_l2_leaf_reg', 0.5, 8.0)\n",
    "    hp['cat_meta_early_stopping'] = trial.suggest_int('cat_meta_early_stopping', 10, 50, step=10)\n",
    "\n",
    "    # Optimización de períodos para el modelo principal\n",
    "    n_periods_main = trial.suggest_int('n_periods_main', 5, 15)\n",
    "    main_periods = []\n",
    "    for i in range(n_periods_main):\n",
    "        period_main = trial.suggest_int(f'period_main_{i}', 5, 200, log=True)\n",
    "        main_periods.append(period_main)\n",
    "    main_periods = sorted(list(set(main_periods)))\n",
    "    hp['periods_main'] = main_periods\n",
    "\n",
    "    # Optimización de períodos para el meta-modelo\n",
    "    n_periods_meta = 1 #trial.suggest_int('n_periods_meta', 1, 2)\n",
    "    meta_periods = []\n",
    "    for i in range(n_periods_meta):\n",
    "        period_meta = trial.suggest_int(f'period_meta_{i}', 3, 7)\n",
    "        meta_periods.append(period_meta)\n",
    "    meta_periods = sorted(list(set(meta_periods)))\n",
    "    hp['periods_meta'] = meta_periods\n",
    "\n",
    "    # Selección de estadísticas para el modelo principal\n",
    "    main_stat_choices = [\n",
    "        \"std\", \"skew\", \"kurt\", \"zscore\", \"range\", \"mad\", \"entropy\", \n",
    "        \"slope\", \"momentum\", \"fractal\", \"hurst\", \"autocorr\", \"max_dd\", \n",
    "        \"sharpe\", \"fisher\", \"chande\", \"var\", \"approx_entropy\", \n",
    "        \"eff_ratio\", \"corr_skew\", \"jump_vol\", \"vol_skew\"\n",
    "    ]\n",
    "\n",
    "    n_main_stats = trial.suggest_int('n_main_stats', 1, 5)\n",
    "    selected_main_stats = []\n",
    "    for i in range(n_main_stats):\n",
    "        stat = trial.suggest_categorical(f'main_stat_{i}', main_stat_choices)\n",
    "        selected_main_stats.append(stat)\n",
    "    selected_main_stats = list(set(selected_main_stats))\n",
    "    if len(selected_main_stats) == 1 and (\"fractal\" in selected_main_stats or \"hurst\" in selected_main_stats or \"kurt\" in selected_main_stats):\n",
    "        remaining_stats = [s for s in main_stat_choices if s != \"fractal\" and s != \"hurst\" and s != \"kurt\"]\n",
    "        additional_stat = trial.suggest_categorical('additional_stat', remaining_stats)\n",
    "        selected_main_stats.append(additional_stat)\n",
    "    hp[\"stats_main\"] = selected_main_stats\n",
    "    #print(f\"Main features seleccionadas: {hp['stats_main']}\")\n",
    "\n",
    "    # Selección de estadísticas para el meta-modelo\n",
    "    meta_stat_choices = [\n",
    "        \"std\", \"skew\", \"kurt\", \"zscore\", \"range\", \"mad\", \"entropy\", \n",
    "        \"slope\", \"momentum\", \"fractal\", \"hurst\", \"autocorr\", \"max_dd\", \n",
    "        \"sharpe\", \"fisher\", \"chande\", \"var\", \"approx_entropy\", \n",
    "        \"eff_ratio\", \"corr_skew\", \"jump_vol\", \"vol_skew\"\n",
    "    ]\n",
    "    # Seleccionar estadísticas meta\n",
    "    n_meta_stats = trial.suggest_int('n_meta_stats', 1, 2)\n",
    "    selected_meta_stats = []\n",
    "    for i in range(n_meta_stats):\n",
    "        stat = trial.suggest_categorical(f'meta_stat_{i}', meta_stat_choices)\n",
    "        selected_meta_stats.append(stat)\n",
    "    selected_meta_stats = list(set(selected_meta_stats))\n",
    "    hp[\"stats_meta\"] = selected_meta_stats\n",
    "    #print(f\"Meta features seleccionadas: {hp['stats_meta']} | Periodo: {hp['periods_meta']}\")\n",
    "\n",
    "    # Dataset completo\n",
    "    full_ds = get_features(base_hp['base_df'], hp)\n",
    "    \n",
    "    # Dividir en períodos de entrenamiento, backward testing y forward testing\n",
    "    train_mask = (full_ds.index > hp['backward']) & (full_ds.index < hp['forward'])\n",
    "    oos_mask = (full_ds.index >= hp['forward']) & (full_ds.index < hp['full_forward'])\n",
    "    ds_train = full_ds.loc[train_mask]\n",
    "    ds_oos = full_ds.loc[oos_mask]\n",
    "    ds_train_val = ds_train.iloc[-len(ds_oos):]\n",
    "    \n",
    "    # Clustering con ventana deslizante\n",
    "    assert ds_train.index.max() < hp['forward'], \\\n",
    "       \"¡ds_train contiene fechas posteriores al límite forward!\"\n",
    "    assert ds_oos.index.min() >= hp['forward'], \\\n",
    "        \"¡ds_oos incluye datos dentro del tramo backward!\"\n",
    "    data = sliding_window_clustering(\n",
    "        ds_train,\n",
    "        n_clusters=hp['n_clusters'],\n",
    "        window_size=hp['window_size'],\n",
    "        vol_period=hp['vol_period']\n",
    "    )\n",
    "    \n",
    "    best_combined_score = -math.inf\n",
    "    \n",
    "    # Calcular umbral mínimo adaptativo basado en el tamaño del dataset\n",
    "    # total_samples = len(data)\n",
    "    # min_samples_percent = 0.02  # 2% del total de muestras como mínimo\n",
    "    # min_samples_absolute = 200  # Mínimo absoluto\n",
    "    # min_samples_required = max(min_samples_absolute, int(total_samples * min_samples_percent))\n",
    "    \n",
    "    # Evaluar clusters ordenados por tamaño\n",
    "    cluster_sizes = data['clusters'].value_counts()\n",
    "    for clust in cluster_sizes.index:\n",
    "        clustered_data = data.loc[data['clusters'] == clust]\n",
    "\n",
    "        clustered_data = get_labels_one_direction(\n",
    "            clustered_data,\n",
    "            markup=hp['markup'],\n",
    "            min=hp['label_min'],\n",
    "            max=hp['label_max'],\n",
    "            direction=hp['direction'])\n",
    "\n",
    "        clustered_data = clustered_data.drop(['close', 'clusters'], axis=1)\n",
    "        meta_data = data.copy()\n",
    "        meta_data['clusters'] = (meta_data['clusters'] == clust).astype(int)\n",
    "\n",
    "        # ── descartar clusters problemáticos ────────────────────────────\n",
    "        label_counts  = clustered_data['labels'].value_counts()\n",
    "        meta_counts   = meta_data['clusters'].value_counts()\n",
    "        # 1) mínimo de muestras totales\n",
    "        #if len(clustered_data) < min_samples_required:\n",
    "        #    continue\n",
    "        # 2) labels: deben existir las 2 clases y ≥ 5 ejemplos cada una\n",
    "        if len(label_counts) < 2 or (label_counts < 5).any():\n",
    "            continue\n",
    "        # 3) meta-labels: idem (clusters 0 / 1)\n",
    "        if len(meta_counts) < 2 or (meta_counts < 5).any():\n",
    "            continue\n",
    "\n",
    "        # Evaluación en ambos períodos\n",
    "        R2_forward, R2_backward, model_main, meta_model = fit_final_models(\n",
    "            clustered_data,\n",
    "            meta_data.drop(['close'], axis=1),\n",
    "            ds_oos,\n",
    "            ds_train_val,\n",
    "            hp\n",
    "        )\n",
    "\n",
    "        # Calcular puntuación combinada (puedes ajustar los pesos según necesites)\n",
    "        # reemplaza todo el bloque anterior por:\n",
    "        score = calc_score(R2_forward, R2_backward)\n",
    "        if score <= -1.0:\n",
    "            continue  \n",
    "\n",
    "        if score > best_combined_score:\n",
    "            best_combined_score = score\n",
    "            # Guardar información del trial actual\n",
    "            trial.set_user_attr(\"forward_r2\", R2_forward)\n",
    "            trial.set_user_attr(\"backward_r2\", R2_backward)\n",
    "            trial.set_user_attr(\"combined_score\", score)\n",
    "            trial.set_user_attr(\"cluster_id\", clust)\n",
    "            trial.set_user_attr(\"stats_main\", hp[\"stats_main\"])\n",
    "            trial.set_user_attr(\"stats_meta\", hp[\"stats_meta\"])\n",
    "            trial.set_user_attr(\"periods_main\", hp[\"periods_main\"])\n",
    "            trial.set_user_attr(\"periods_meta\", hp[\"periods_meta\"])\n",
    "            # Guardar parámetros del trial actual (sin fechas)\n",
    "            params_to_save = hp.copy()\n",
    "            params_to_save.pop('backward', None)\n",
    "            params_to_save.pop('forward', None)\n",
    "            params_to_save.pop('full_forward', None)\n",
    "            trial.set_user_attr(\"params\", params_to_save)\n",
    "            # Si existe el estudio, actualizar sus atributos\n",
    "            if study is not None:\n",
    "                current_best = study.user_attrs.get(\"best_combined_score\", -math.inf)\n",
    "                if score > current_best:\n",
    "                    study.set_user_attr(\"best_params\", params_to_save)\n",
    "                    study.set_user_attr(\"best_metrics\", {\n",
    "                        \"forward_r2\": R2_forward,\n",
    "                        \"backward_r2\": R2_backward,\n",
    "                        \"combined_score\": score,\n",
    "                        \"cluster_id\": clust,\n",
    "                    })\n",
    "                    study.set_user_attr(\"best_combined_score\", score)\n",
    "                    study.set_user_attr(\"best_models\", [model_main, meta_model])\n",
    "                    study.set_user_attr(\"best_stats_main\", hp[\"stats_main\"])\n",
    "                    study.set_user_attr(\"best_stats_meta\", hp[\"stats_meta\"])\n",
    "                    study.set_user_attr(\"best_periods_main\", hp[\"periods_main\"])\n",
    "                    study.set_user_attr(\"best_periods_meta\", hp[\"periods_meta\"])\n",
    "                    study.set_user_attr(\"best_trial_number\", trial.number)\n",
    "                    study.set_user_attr(\"best_df_sample\", full_ds.sample(1))\n",
    "    # Si no hay ningún cluster válido, devolver un valor negativo pero no infinito\n",
    "    if best_combined_score == -math.inf:\n",
    "        return -10.0\n",
    "\n",
    "    # No aplicar penalización adicional por pocos clusters para mantener coherencia\n",
    "    return best_combined_score\n",
    "\n",
    "def optimize_and_export(base_hp: Dict[str, Any]):\n",
    "    \"\"\"Lanza Optuna, guarda el mejor modelo y lo exporta a ONNX.\"\"\"\n",
    "    def show_best_summary(study: optuna.study.Study, model_seed) -> None:\n",
    "        \"\"\"Muestra en un único cuadro el resultado óptimo del estudio.\"\"\"\n",
    "        # ── extraer métricas y modelos ───────────────────────────────────────\n",
    "        m  = study.user_attrs.get(\"best_metrics\", {})\n",
    "        f2 = m.get(\"forward_r2\",   float(\"nan\"))\n",
    "        b2 = m.get(\"backward_r2\",  float(\"nan\"))\n",
    "        c2 = m.get(\"combined_score\", float(\"nan\"))\n",
    "        best_trial = study.user_attrs.get(\"best_trial_number\", \"-\")\n",
    "        best_df_sample = study.user_attrs.get(\"best_df_sample\", None)\n",
    "\n",
    "        main_cls = meta_cls = \"None\"\n",
    "        best_models = study.user_attrs.get(\"best_models\")\n",
    "        if best_models and len(best_models) == 2:\n",
    "            main_cls = type(best_models[0]).__name__\n",
    "            meta_cls = type(best_models[1]).__name__\n",
    "\n",
    "        # ── cuadro de resumen ────────────────────────────────────────────────\n",
    "        lines = [\n",
    "            \"┌\" + \"─\" * 55 + \"┐\",\n",
    "            f\"│  MODELO {model_seed} TRIAL ÓPTIMO #{best_trial}\",\n",
    "            \"├\" + \"─\" * 55 + \"┤\",\n",
    "            f\"│  R² Forward : {f2:10.4f}  │  R² Backward : {b2:10.4f} │\",\n",
    "            f\"│  Combined     : {c2:10.4f}                            │\",\n",
    "            \"├\" + \"─\" * 55 + \"┤\"\n",
    "        ]\n",
    "        print(\"\\n\".join(lines))\n",
    "\n",
    "        #debug\n",
    "        # if best_df_sample is not None:\n",
    "        #     pd.set_option('display.max_columns', None)\n",
    "        #     pd.set_option('display.width', None)\n",
    "        #     pd.set_option('display.max_colwidth', None)\n",
    "        #     display(best_df_sample)\n",
    "\n",
    "    base_hp.update({\n",
    "        'model_seed': random.randint(0, 10000000),\n",
    "    })\n",
    "    # Configurar el pruner inteligente\n",
    "    # pruner = SuccessiveHalvingPruner(\n",
    "    #     min_resource=1,\n",
    "    #     reduction_factor=3,\n",
    "    #     min_early_stopping_rate=0\n",
    "    # )\n",
    "\n",
    "    # Crear el estudio sin persistencia\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        pruner=HyperbandPruner(),\n",
    "        sampler=optuna.samplers.TPESampler(\n",
    "            n_startup_trials=int(np.sqrt(base_hp['n_trials'])),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    study.optimize(lambda t: objective(t, base_hp, study),\n",
    "                n_trials=base_hp['n_trials'],\n",
    "                show_progress_bar=True)\n",
    "\n",
    "    # ── verificación y cuadro ───────────────────────────────\n",
    "    best_trial = study.best_trial\n",
    "    assert study.user_attrs.get(\"best_trial_number\") == best_trial.number, \\\n",
    "        \"best_trial_number no coincide con study.best_trial.number\"\n",
    "\n",
    "    best_metric_saved = study.user_attrs.get(\"best_metrics\", {}).get(\"combined_score\")\n",
    "    if best_metric_saved is not None:\n",
    "        assert math.isclose(best_metric_saved, study.best_value, rel_tol=1e-9), \\\n",
    "            \"combined_score guardado ≠ study.best_value\"\n",
    "    else:\n",
    "        print(\"⚠️  Ningún trial produjo un score válido; modelos no guardados.\")\n",
    "\n",
    "    best_models = study.user_attrs.get(\"best_models\")\n",
    "    assert best_models and len(best_models) == 2 and all(best_models), \\\n",
    "        \"best_models incorrecto\"\n",
    "\n",
    "    show_best_summary(study, base_hp['model_seed'])\n",
    "\n",
    "    # ── exportación ─────────────────────────────────────────\n",
    "    print(\"Exportando modelos ONNX…\")\n",
    "    export_params = base_hp.copy()\n",
    "    export_params.update({\n",
    "        \"best_trial\": study.user_attrs[\"best_trial_number\"],\n",
    "        \"best_score\": study.user_attrs[\"best_combined_score\"],\n",
    "        \"best_periods_main\": study.user_attrs[\"best_periods_main\"],\n",
    "        \"best_periods_meta\": study.user_attrs[\"best_periods_meta\"],\n",
    "        \"best_stats_main\"  : study.user_attrs[\"best_stats_main\"],\n",
    "        \"best_stats_meta\"  : study.user_attrs[\"best_stats_meta\"],\n",
    "        \"best_models\"      : study.user_attrs[\"best_models\"],\n",
    "    })\n",
    "    export_model_to_ONNX(**export_params)\n",
    "    # ── devolver métricas ─────────────────────────────────────────\n",
    "    return {\n",
    "        \"forward_r2\"   : study.user_attrs.get(\"best_metrics\", {}).get(\"forward_r2\",   float(\"nan\")),\n",
    "        \"backward_r2\"  : study.user_attrs.get(\"best_metrics\", {}).get(\"backward_r2\",  float(\"nan\")),\n",
    "        \"combined_score\": study.user_attrs.get(\"best_metrics\", {}).get(\"combined_score\", float(\"nan\")),\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_hp: Dict[str, Any] = {\n",
    "        'symbol': r'XAUUSD',\n",
    "        'timeframe': 'H1',\n",
    "        'direction': 'buy',\n",
    "        'backward': datetime(2020, 2, 1),\n",
    "        'forward': datetime(2024, 2, 1),\n",
    "        'full_forward': datetime(2026, 2, 1),\n",
    "        'model_seed': 0,\n",
    "        'n_trials': 1000,\n",
    "        'models_export_path': r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/',\n",
    "        'include_export_path': r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Include/ajmtrz/include/Dmitrievsky',\n",
    "        'history_path': r\"/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/Common/Files/\",\n",
    "        'stats_main': [],\n",
    "        'stats_meta': [],\n",
    "        'best_models': [None, None],\n",
    "        'markup': 0.20,\n",
    "        'label_min'  : 1,\n",
    "        'label_max'  : 15,\n",
    "        'n_clusters': 30,\n",
    "        'window_size': 350,\n",
    "        'periods_main': [i for i in range(5, 300, 30)],\n",
    "        'periods_meta': [5],\n",
    "    }\n",
    "    base_df = get_prices(base_hp)\n",
    "    base_hp.update({\n",
    "        'base_df': base_df,\n",
    "    })\n",
    "    # Para recopilar resultados globales de todos los modelos\n",
    "    all_results = {}\n",
    "    best_models = []\n",
    "    model_range = range(0, 10)\n",
    "    base_hp.update({\n",
    "        'n_trials': 1000,\n",
    "    })\n",
    "    for i in tqdm(model_range, desc=f\"Optimizando {base_hp['symbol']}/{base_hp['timeframe']}\", unit=\"modelo\"):\n",
    "        try:\n",
    "            model_results = optimize_and_export(base_hp)\n",
    "            best_models.append((i, model_results))\n",
    "            \n",
    "            # Añadir a resultados globales\n",
    "            all_results[f\"model_{i}\"] = {\n",
    "                \"success\": True,\n",
    "                \"forward_r2\": model_results[\"forward_r2\"],\n",
    "                \"backward_r2\": model_results[\"backward_r2\"],\n",
    "                \"combined_score\": model_results[\"combined_score\"]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            tqdm.write(f\"\\nError procesando modelo {i}: {str(e)}\")\n",
    "            tqdm.write(traceback.format_exc())\n",
    "            \n",
    "            all_results[f\"model_{i}\"] = {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "            continue\n",
    "    \n",
    "    # Resumen final\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"RESUMEN DE OPTIMIZACIÓN {base_hp['symbol']}/{base_hp['timeframe']}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    successful_models = [info for model_key, info  in all_results.items() if info.get(\"success\", False)]\n",
    "    print(f\"Modelos completados exitosamente: {len(successful_models)}/{len(model_range)}\")\n",
    "    \n",
    "    if successful_models:\n",
    "        # Calcular estadísticas globales\n",
    "        forward_scores = [info[\"forward_r2\"] for info in successful_models]\n",
    "        backward_scores = [info[\"backward_r2\"] for info in successful_models]\n",
    "        combined_scores = [info[\"combined_score\"] for info in successful_models]\n",
    "        \n",
    "        print(f\"\\nEstadísticas de rendimiento:\")\n",
    "        print(f\"  Forward R2 promedio: {np.mean(forward_scores):.4f} ± {np.std(forward_scores):.4f}\")\n",
    "        print(f\"  Backward R2 promedio: {np.mean(backward_scores):.4f} ± {np.std(backward_scores):.4f}\")\n",
    "        print(f\"  Puntuación combinada promedio: {np.mean(combined_scores):.4f} ± {np.std(combined_scores):.4f}\")\n",
    "\n",
    "        # Identificar el mejor modelo global basado en la puntuación combinada\n",
    "        successful = [(k, v) for k, v in all_results.items() if v.get(\"success\", False)]\n",
    "        combined_scores = [v[\"combined_score\"] for _, v in successful]\n",
    "        best_model_key, best_info = successful[int(np.argmax(combined_scores))]\n",
    "        \n",
    "        print(f\"\\nMejor modelo global: {best_model_key}\")\n",
    "        print(f\"  Forward R2: {best_info['forward_r2']:.4f}\")\n",
    "        print(f\"  Backward R2: {best_info['backward_r2']:.4f}\")\n",
    "        print(f\"  Puntuación combinada: {best_info['combined_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nProceso de optimización completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
