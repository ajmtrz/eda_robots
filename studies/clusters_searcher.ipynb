{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15736753",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e880b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from numba import njit\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner, HyperbandPruner\n",
    "from optuna.storages import RDBStorage\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.labeling_lib import get_prices\n",
    "from modules.labeling_lib import get_clustering_features\n",
    "from modules.labeling_lib import get_labels_one_direction\n",
    "from modules.labeling_lib import sliding_window_clustering\n",
    "from modules.tester_lib import test_model_one_direction_clustering\n",
    "from modules.export_lib import export_model_to_ONNX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def fit_final_models(clustered: pd.DataFrame,\n",
    "                     meta: pd.DataFrame,\n",
    "                     oos_data: pd.DataFrame,\n",
    "                     backward_data: pd.DataFrame,\n",
    "                     hp: Dict[str, Any]) -> Tuple[float, float, Any, Any]:\n",
    "    \"\"\"Entrena modelo principal + meta‑modelo y evalúa en OOS y backward.\n",
    "\n",
    "    Devuelve (R2_forward, R2_backward, model, meta_model).\n",
    "    \"\"\"\n",
    "    # ---------- 1) main model ----------\n",
    "    X_main = clustered.drop(columns=['labels', *meta.columns[meta.columns.str.contains('_meta_feature')]])\n",
    "    y_main = clustered['labels'].astype('int16')\n",
    "\n",
    "    # ---------- 2) meta‑model ----------\n",
    "    X_meta = meta.loc[:, meta.columns.str.contains('_meta_feature')]\n",
    "    y_meta = meta['clusters'].astype('int16')\n",
    "    \n",
    "    # 3) Split aleatorio (70/30)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_main, y_main, train_size=0.7, shuffle=True)\n",
    "    train_X_m, test_X_m, train_y_m, test_y_m = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.7, shuffle=True)\n",
    "\n",
    "    # 4) Hiper‑parámetros CatBoost (con valores por defecto + overrides)\n",
    "    cat_main_params = dict(\n",
    "        iterations=hp.get('cat_main_iterations', 500),\n",
    "        depth=hp.get('cat_main_depth', 6),\n",
    "        learning_rate=hp.get('cat_main_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_main_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['Accuracy'],\n",
    "        eval_metric='Accuracy',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    model = CatBoostClassifier(**cat_main_params)\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), early_stopping_rounds=25)\n",
    "\n",
    "    cat_meta_params = dict(\n",
    "        iterations=hp.get('cat_meta_iterations', 500),\n",
    "        depth=hp.get('cat_meta_depth', 6),\n",
    "        learning_rate=hp.get('cat_meta_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_meta_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['F1'],\n",
    "        eval_metric='F1',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    meta_model = CatBoostClassifier(**cat_meta_params)\n",
    "    meta_model.fit(train_X_m, train_y_m, eval_set=(test_X_m, test_y_m), early_stopping_rounds=15)\n",
    "\n",
    "    # 5) Evaluación en datos fuera de muestra (forward)\n",
    "    R2_forward = test_model_one_direction_clustering(\n",
    "        oos_data,\n",
    "        [model, meta_model],\n",
    "        hp['full forward'],\n",
    "        hp['forward'],\n",
    "        hp['markup'],\n",
    "        hp['direction'],\n",
    "        plt=False,\n",
    "    )\n",
    "    if math.isnan(R2_forward):\n",
    "        R2_forward = -1.0\n",
    "        \n",
    "    # 6) Evaluación en datos históricos (backward)\n",
    "    R2_backward = test_model_one_direction_clustering(\n",
    "        backward_data,\n",
    "        [model, meta_model],\n",
    "        hp['forward'],\n",
    "        hp['backward'],\n",
    "        hp['markup'],\n",
    "        hp['direction'],\n",
    "        plt=False,\n",
    "    )\n",
    "    if math.isnan(R2_backward):\n",
    "        R2_backward = -1.0\n",
    "        \n",
    "    return R2_forward, R2_backward, model, meta_model\n",
    "\n",
    "def objective(trial: optuna.trial.Trial, base_hp: Dict[str, Any], study=None, best_models=None) -> float:\n",
    "    # Añadir estrategia de warm start para mejorar la eficiencia\n",
    "    if study is not None and len(study.trials) > 5:\n",
    "        completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        \n",
    "        # Con 25% de probabilidad, reutilizar parámetros de uno de los 3 mejores trials\n",
    "        if random.random() < 0.25 and completed_trials:\n",
    "            # Ordenar trials por valor\n",
    "            sorted_trials = sorted(completed_trials, \n",
    "                                  key=lambda t: t.value if t.value is not None else float('-inf'),\n",
    "                                  reverse=True)\n",
    "            \n",
    "            # Seleccionar uno de los 3 mejores trials aleatoriamente\n",
    "            top_n = min(3, len(sorted_trials))\n",
    "            if top_n > 0:\n",
    "                reference_trial = sorted_trials[random.randint(0, top_n-1)]\n",
    "                \n",
    "                # Aplicar una pequeña perturbación a los valores\n",
    "                for param_name, param_value in reference_trial.params.items():\n",
    "                    try:\n",
    "                        # No reutilizar si ya se ha sugerido este parámetro\n",
    "                        if param_name in trial.params:\n",
    "                            continue\n",
    "                            \n",
    "                        if isinstance(param_value, int):\n",
    "                            # Para enteros, añadir un pequeño ruido\n",
    "                            noise = random.randint(-2, 2)\n",
    "                            # Garantizar valor mínimo de 1 para parámetros enteros\n",
    "                            new_value = max(1, param_value + noise)\n",
    "                            trial.suggest_int(param_name, new_value, new_value)\n",
    "                        elif isinstance(param_value, float):\n",
    "                            # Para flotantes, añadir ruido porcentual\n",
    "                            noise_factor = random.uniform(-0.2, 0.2)\n",
    "                            # Garantizar que el valor mínimo sea positivo\n",
    "                            min_allowed = 0.001 if param_name.endswith('learning_rate') else 0.1\n",
    "                            new_value = max(min_allowed, param_value * (1 + noise_factor))\n",
    "                            trial.suggest_float(param_name, new_value, new_value)\n",
    "                    except:\n",
    "                        # Si falla, continuamos con la sugerencia normal\n",
    "                        pass\n",
    "    \n",
    "    # Resto del código original\n",
    "    hp = base_hp.copy()\n",
    "\n",
    "    # µ··· Espacio de búsqueda optimizado ···µ\n",
    "    # Parámetros de clustering más amplios para encontrar patrones más diversos\n",
    "    hp['n_clusters'] = trial.suggest_int('n_clusters', 5, 50, step=5)  \n",
    "    hp['window_size'] = trial.suggest_int('window_size', 50, 500, step=10)\n",
    "    \n",
    "    # Parámetros de etiquetado más agresivos\n",
    "    hp['label_min'] = trial.suggest_int('label_min', 1, 5)\n",
    "    hp['label_max'] = trial.suggest_int('label_max', hp['label_min']+5, 30)\n",
    "    hp['markup'] = trial.suggest_float(\"markup\", 0.1, 0.4)\n",
    "\n",
    "    # CatBoost principal - Mayor capacidad de aprendizaje\n",
    "    hp['cat_main_iterations'] = trial.suggest_int('cat_main_iterations', 300, 2000, step=100)\n",
    "    hp['cat_main_depth'] = trial.suggest_int('cat_main_depth', 6, 12)\n",
    "    hp['cat_main_learning_rate'] = trial.suggest_float('cat_main_learning_rate', 0.005, 0.4, log=True)\n",
    "    hp['cat_main_l2_leaf_reg'] = trial.suggest_float('cat_main_l2_leaf_reg', 0.5, 10.0)\n",
    "\n",
    "    # CatBoost meta - Enfoque en precisión\n",
    "    hp['cat_meta_iterations'] = trial.suggest_int('cat_meta_iterations', 200, 1000, step=100)\n",
    "    hp['cat_meta_depth'] = trial.suggest_int('cat_meta_depth', 5, 10)\n",
    "    hp['cat_meta_learning_rate'] = trial.suggest_float('cat_meta_learning_rate', 0.01, 0.3, log=True)\n",
    "    hp['cat_meta_l2_leaf_reg'] = trial.suggest_float('cat_meta_l2_leaf_reg', 0.5, 8.0)\n",
    "\n",
    "    # Optimización de períodos para el modelo principal\n",
    "    n_periods_main = trial.suggest_int('n_periods_main', 5, 15)\n",
    "    main_periods = []\n",
    "    for i in range(n_periods_main):\n",
    "        period_main = trial.suggest_int(f'period_main_{i}', 5, 200, log=True)\n",
    "        main_periods.append(period_main)\n",
    "    main_periods = sorted(list(set(main_periods)))  # Eliminar duplicados y ordenar\n",
    "    if len(main_periods) < 3:  # Asegurar mínimo de períodos\n",
    "        return -np.inf\n",
    "    hp['periods_main'] = main_periods\n",
    "\n",
    "    # Optimización de períodos para el meta-modelo\n",
    "    n_periods_meta = 1 #trial.suggest_int('n_periods_meta', 1, 2)\n",
    "    meta_periods = []\n",
    "    for i in range(n_periods_meta):\n",
    "        period_meta = trial.suggest_int(f'period_meta_{i}', 3, 5)\n",
    "        meta_periods.append(period_meta)\n",
    "    meta_periods = sorted(list(set(meta_periods)))  # Eliminar duplicados y ordenar\n",
    "    hp['periods_meta'] = meta_periods\n",
    "\n",
    "    # Selección de estadísticas para el modelo principal\n",
    "    main_stat_choices = [\n",
    "        \"std\", \"skew\", \"kurt\", \"zscore\", \"mean\", \"range\", \"median\", \n",
    "        \"mad\", \"var\", \"entropy\", \"slope\", \"momentum\", \"roc\", \"fractal\", \"hurst\"\n",
    "    ]\n",
    "    n_main_stats = trial.suggest_int('n_main_stats', 1, 5)\n",
    "    selected_main_stats = []\n",
    "    for i in range(n_main_stats):\n",
    "        stat = trial.suggest_categorical(f'main_stat_{i}', main_stat_choices)\n",
    "        selected_main_stats.append(stat)\n",
    "    selected_main_stats = list(set(selected_main_stats))\n",
    "    if len(selected_main_stats) == 1 and \"fractal\" in selected_main_stats:\n",
    "        remaining_stats = [s for s in main_stat_choices if s != \"fractal\"]\n",
    "        additional_stat = trial.suggest_categorical('additional_stat', remaining_stats)\n",
    "        selected_main_stats.append(additional_stat)\n",
    "    hp[\"stats_main\"] = selected_main_stats\n",
    "    #print(f\"Main features seleccionadas: {hp['stats_main']}\")\n",
    "\n",
    "    # Selección de estadísticas para el meta-modelo\n",
    "    meta_stat_choices = [\n",
    "        \"std\", \"skew\", \"zscore\", \"range\", \"mad\", \n",
    "        \"var\", \"entropy\", \"slope\", \"momentum\", \"roc\"\n",
    "    ]\n",
    "    # Seleccionar una única estadística meta\n",
    "    selected_meta_stat = trial.suggest_categorical('meta_stat', meta_stat_choices)\n",
    "    hp[\"stats_meta\"] = [selected_meta_stat]\n",
    "    #print(f\"Meta features seleccionadas: {hp['stats_meta']}\")\n",
    "\n",
    "    # Dataset completo\n",
    "    full_ds = get_clustering_features(get_prices(hp), hp)\n",
    "    \n",
    "    # Dividir en períodos de entrenamiento, backward testing y forward testing\n",
    "    ds_train = full_ds[(full_ds.index > hp['backward']) & (full_ds.index < hp['forward'])]\n",
    "    ds_backward = full_ds[full_ds.index <= hp['backward']]  # Datos para backward testing\n",
    "    ds_oos = full_ds[(full_ds.index >= hp['forward']) & (full_ds.index < hp['full forward'])]\n",
    "    \n",
    "    # Clustering con ventana deslizante\n",
    "    data = sliding_window_clustering(\n",
    "        ds_train,\n",
    "        n_clusters=hp['n_clusters'],\n",
    "        window_size=hp['window_size']\n",
    "    )\n",
    "    \n",
    "    best_combined_score = -math.inf\n",
    "    valid_clusters = 0\n",
    "    \n",
    "    # Calcular umbral mínimo adaptativo basado en el tamaño del dataset\n",
    "    total_samples = len(data)\n",
    "    min_samples_percent = 0.05  # 5% del total de muestras como mínimo\n",
    "    min_samples_absolute = 200  # Mínimo absoluto\n",
    "    min_samples_required = max(min_samples_absolute, int(total_samples * min_samples_percent))\n",
    "    \n",
    "    # Evaluar clusters ordenados por tamaño\n",
    "    cluster_sizes = data['clusters'].value_counts()\n",
    "    for clust in cluster_sizes.index:\n",
    "        clustered_data = data[data['clusters'] == clust].copy()\n",
    "        if len(clustered_data) < min_samples_required:\n",
    "            continue\n",
    "            \n",
    "        valid_clusters += 1\n",
    "        clustered_data = get_labels_one_direction(\n",
    "            clustered_data,\n",
    "            markup=hp['markup'],\n",
    "            min=hp['label_min'],\n",
    "            max=hp['label_max'],\n",
    "            direction=hp['direction'])\n",
    "\n",
    "        clustered_data = clustered_data.drop(['close', 'clusters'], axis=1)\n",
    "        meta_data = data.copy()\n",
    "        meta_data['clusters'] = (meta_data['clusters'] == clust).astype(int)\n",
    "\n",
    "        # Evaluación en ambos períodos\n",
    "        R2_forward, R2_backward, model, meta_model = fit_final_models(\n",
    "            clustered_data,\n",
    "            meta_data.drop(['close'], axis=1),\n",
    "            ds_oos,\n",
    "            ds_backward,\n",
    "            hp\n",
    "        )\n",
    "\n",
    "        # Calcular puntuación combinada (puedes ajustar los pesos según necesites)\n",
    "        # Esto prioriza modelos con buen rendimiento en ambos períodos\n",
    "        forward_weight = 0.6  # Peso para el período forward\n",
    "        backward_weight = 0.4  # Peso para el período backward\n",
    "        \n",
    "        # Penalización por diferencia excesiva (inconsistencia)\n",
    "        consistency_penalty = 1.0\n",
    "        diff = abs(R2_forward - R2_backward)\n",
    "        if diff > 0.3:  # Si la diferencia es mayor al 30%\n",
    "            consistency_penalty = 0.7  # Penalización del 30%\n",
    "        \n",
    "        # Cálculo de la puntuación combinada\n",
    "        combined_score = ((R2_forward * forward_weight) + \n",
    "                          (R2_backward * backward_weight)) * consistency_penalty\n",
    "        \n",
    "        # Si ambos scores son negativos, el modelo es malo en ambos períodos\n",
    "        # Recordar que fit_final_models asigna -1.0 a R2 cuando es NaN\n",
    "        if R2_forward <= -1.0 and R2_backward <= -1.0:\n",
    "            combined_score = -1.0\n",
    "            \n",
    "        # Si hay diferencia de signo, el modelo es inconsistente\n",
    "        if (R2_forward > 0 and R2_backward <= -1.0) or (R2_forward <= -1.0 and R2_backward > 0):\n",
    "            combined_score *= 0.5  # Penalización adicional\n",
    "\n",
    "        if combined_score > best_combined_score:\n",
    "            best_combined_score = combined_score\n",
    "            best_models[0] = model\n",
    "            best_models[1] = meta_model\n",
    "            # Guardar información del trial actual\n",
    "            trial.set_user_attr(\"forward_r2\", R2_forward)\n",
    "            trial.set_user_attr(\"backward_r2\", R2_backward)\n",
    "            trial.set_user_attr(\"combined_score\", combined_score)\n",
    "            trial.set_user_attr(\"cluster_id\", clust)\n",
    "            # Guardar parámetros del trial actual (sin fechas)\n",
    "            params_to_save = hp.copy()\n",
    "            params_to_save.pop('backward', None)\n",
    "            params_to_save.pop('forward', None)\n",
    "            params_to_save.pop('full forward', None)\n",
    "            trial.set_user_attr(\"params\", params_to_save)\n",
    "            if study is not None:\n",
    "                prev_best = study.user_attrs.get(\"best_combined_score\", -np.inf)\n",
    "                if best_combined_score > prev_best:\n",
    "                    # Guardar información del mejor modelo encontrado\n",
    "                    study.set_user_attr(\"best_params\", params_to_save)\n",
    "                    study.set_user_attr(\"best_metrics\", {\n",
    "                        \"forward_r2\": R2_forward,\n",
    "                        \"backward_r2\": R2_backward,\n",
    "                        \"combined_score\": combined_score,\n",
    "                        \"cluster_id\": clust\n",
    "                    })\n",
    "                    study.set_user_attr(\"best_combined_score\", best_combined_score)\n",
    "                    study.set_user_attr(\"best_stats_main\", hp[\"stats_main\"])\n",
    "                    study.set_user_attr(\"best_stats_meta\", hp[\"stats_meta\"])\n",
    "                    study.set_user_attr(\"best_periods\", hp[\"periods_main\"])\n",
    "                    study.set_user_attr(\"best_periods_meta\", hp[\"periods_meta\"])\n",
    "                    # Guardar información del mejor trial\n",
    "                    study.set_user_attr(\"best_trial_number\", trial.number)\n",
    "                    study.set_user_attr(\"best_trial_date\", datetime.now().isoformat())\n",
    "                \n",
    "    # Penalizar si muy pocos clusters válidos\n",
    "    if valid_clusters < 3:\n",
    "        best_combined_score *= 0.5\n",
    "        \n",
    "    # Si no hay ningún cluster válido, devolver un valor negativo pero no infinito\n",
    "    if best_combined_score == -math.inf:\n",
    "        return -10.0  # Valor negativo pero finito\n",
    "\n",
    "    return best_combined_score\n",
    "\n",
    "def optimize_and_export(symbol, timeframe, model_number, n_trials):\n",
    "    \"\"\"Lanza Optuna, guarda el mejor modelo y lo exporta a ONNX.\"\"\"\n",
    "\n",
    "    common_file_folder = r\"/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/Common/Files/\"\n",
    "    mql5_files_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/'\n",
    "    mql5_include_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Include/ajmtrz/include/Dmitrievsky'\n",
    "\n",
    "    # Crear directorio para la base de datos si no existe\n",
    "    db_dir = os.path.join(mql5_files_folder, 'optuna_db')\n",
    "    os.makedirs(db_dir, exist_ok=True)\n",
    "    db_path = os.path.join(db_dir, f'{symbol}_{timeframe}_study.db')\n",
    "\n",
    "    # Configurar el pruner inteligente\n",
    "    pruner = SuccessiveHalvingPruner(\n",
    "        min_resource=1,\n",
    "        reduction_factor=3,\n",
    "        min_early_stopping_rate=0\n",
    "    )\n",
    "\n",
    "    # Crear el estudio con persistencia\n",
    "    storage = RDBStorage(f\"sqlite:///{db_path}\")\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize',\n",
    "        pruner=pruner,\n",
    "        storage=storage,\n",
    "        load_if_exists=True,\n",
    "        study_name=f\"{symbol}_{timeframe}_model{model_number}_study\",\n",
    "        sampler=optuna.samplers.TPESampler()\n",
    "    )\n",
    "\n",
    "    base_hp: Dict[str, Any] = {\n",
    "        'symbol': symbol,\n",
    "        'timeframe': timeframe,\n",
    "        'models_export_path': mql5_files_folder,\n",
    "        'include_export_path': mql5_include_folder,\n",
    "        'history_path': common_file_folder,\n",
    "        'stats_main': [],\n",
    "        'stats_meta': [],  # Por defecto usa std\n",
    "        'model_number': model_number,\n",
    "        'markup': 0.20,\n",
    "        'label_min'  : 1,\n",
    "        'label_max'  : 15,\n",
    "        'direction': 'buy',\n",
    "        'n_clusters': 30,\n",
    "        'window_size': 350,\n",
    "        'periods_main': [i for i in range(5, 300, 30)],\n",
    "        'periods_meta': [5],\n",
    "        'backward': datetime(2020, 3, 26),\n",
    "        'forward': datetime(2024, 1, 1),\n",
    "        'full forward': datetime(2026, 1, 1),\n",
    "    }\n",
    "\n",
    "    # Crear lista mutable para almacenar los mejores modelos\n",
    "    best_models = [None, None]\n",
    "    study.optimize(lambda t: objective(t, base_hp, study, best_models), n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "    print(\"\\n┌───────────────────────────────────────────────┐\")\n",
    "    print(f\"│      MEJOR RESULTADO {model_number} = {study.best_value:.4f}│\")\n",
    "    print(\"└───────────────────────────────────────────────┘\\n\")\n",
    "    print(\"Parámetros óptimos:\\n\", study.best_params)\n",
    "    \n",
    "    # Verificar si hay métricas disponibles en user_attrs\n",
    "    if 'best_metrics' in study.user_attrs:\n",
    "        print(\"Evaluación del mejor modelo:\")\n",
    "        print(f\"  R2 Forward: {study.user_attrs['best_metrics']['forward_r2']:.4f}\")\n",
    "        print(f\"  R2 Backward: {study.user_attrs['best_metrics']['backward_r2']:.4f}\")\n",
    "        print(f\"  Puntuación combinada: {study.user_attrs['best_metrics']['combined_score']:.4f}\")\n",
    "    \n",
    "    # Verificar que ambos modelos existan antes de exportarlos\n",
    "    if best_models[0] is not None and best_models[1] is not None:\n",
    "        print(\"Exportando modelos ONNX...\")\n",
    "        base_hp.update({\n",
    "            \"best_stats_main\": study.user_attrs[\"best_stats_main\"],\n",
    "            \"best_stats_meta\": study.user_attrs[\"best_stats_meta\"],\n",
    "            \"best_periods\": study.user_attrs[\"best_periods\"],\n",
    "            \"best_periods_meta\": study.user_attrs[\"best_periods_meta\"]\n",
    "        })\n",
    "        export_model_to_ONNX(best_models=best_models, **base_hp)\n",
    "        \n",
    "        return {\n",
    "            \"forward_r2\": study.user_attrs.get('best_metrics', {}).get('forward_r2', 0),\n",
    "            \"backward_r2\": study.user_attrs.get('best_metrics', {}).get('backward_r2', 0),\n",
    "            \"combined_score\": study.user_attrs.get('best_metrics', {}).get('combined_score', 0)\n",
    "        }\n",
    "    else:\n",
    "        print(\"⚠️ No se encontraron modelos válidos para exportar\")\n",
    "        return {\n",
    "            \"forward_r2\": 0,\n",
    "            \"backward_r2\": 0,\n",
    "            \"combined_score\": 0\n",
    "        }\n",
    "\n",
    "def cleanup_old_studies(db_path, max_studies=10):\n",
    "    \"\"\"Limpia estudios antiguos manteniendo solo los más recientes.\"\"\"\n",
    "    try:\n",
    "        storage = RDBStorage(f\"sqlite:///{db_path}\")\n",
    "        all_studies = storage.get_all_studies()\n",
    "        \n",
    "        if len(all_studies) > max_studies:\n",
    "            # Ordenar estudios por fecha de creación\n",
    "            sorted_studies = sorted(all_studies, key=lambda x: x.datetime_start)\n",
    "            # Eliminar los más antiguos\n",
    "            for study in sorted_studies[:-max_studies]:\n",
    "                storage.delete_study(study.study_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al limpiar estudios antiguos: {str(e)}\")\n",
    "\n",
    "def verify_optuna_efficiency(symbol, timeframe, model_numbers=None):\n",
    "    \"\"\"Verifica que Optuna está usando la persistencia y optimizando eficientemente.\"\"\"\n",
    "    db_dir = os.path.join(r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/', 'optuna_db')\n",
    "    db_path = os.path.join(db_dir, f'{symbol}_{timeframe}_study.db')\n",
    "    \n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"❌ No se encontró la base de datos: {db_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Verificar el tamaño del archivo para confirmar que contiene datos\n",
    "        file_size = os.path.getsize(db_path) / (1024 * 1024)  # Tamaño en MB\n",
    "        print(f\"✅ Base de datos encontrada ({file_size:.2f} MB)\")\n",
    "        \n",
    "        # Conectar a la base de datos\n",
    "        storage = RDBStorage(f\"sqlite:///{db_path}\")\n",
    "        studies = storage.get_all_study_summaries()\n",
    "        \n",
    "        print(f\"✅ Se encontraron {len(studies)} estudios almacenados\")\n",
    "        \n",
    "        # Si no se especifican modelos, analizar todos\n",
    "        if model_numbers is None:\n",
    "            model_numbers = range(len(studies))\n",
    "        \n",
    "        for model_number in model_numbers:\n",
    "            study_name = f\"{symbol}_{timeframe}_model{model_number}_study\"\n",
    "            \n",
    "            # Buscar el estudio específico\n",
    "            study_summary = None\n",
    "            for summary in studies:\n",
    "                if summary.study_name == study_name:\n",
    "                    study_summary = summary\n",
    "                    break\n",
    "            \n",
    "            if study_summary is None:\n",
    "                print(f\"❌ No se encontró el estudio para el modelo {model_number}\")\n",
    "                continue\n",
    "            \n",
    "            # Cargar el estudio completo\n",
    "            study = optuna.load_study(study_name=study_name, storage=f\"sqlite:///{db_path}\")\n",
    "            \n",
    "            # Analizar la progresión de valores\n",
    "            values = [t.value for t in study.trials if t.value is not None]\n",
    "            if not values:\n",
    "                print(f\"⚠️ El estudio para el modelo {model_number} no tiene trials con valores\")\n",
    "                continue\n",
    "            \n",
    "            # Analizar la mejora progresiva (sign de eficiencia)\n",
    "            best_values = []\n",
    "            current_best = float('-inf')\n",
    "            for v in values:\n",
    "                if v > current_best:\n",
    "                    current_best = v\n",
    "                best_values.append(current_best)\n",
    "            \n",
    "            # Calcular estadísticas\n",
    "            n_trials = len(values)\n",
    "            n_improvements = sum(1 for i in range(1, len(best_values)) if best_values[i] > best_values[i-1])\n",
    "            efficiency = n_improvements / n_trials if n_trials > 0 else 0\n",
    "            \n",
    "            print(f\"\\nModelo {model_number}:\")\n",
    "            print(f\"  Trials totales: {n_trials}\")\n",
    "            print(f\"  Mejoras encontradas: {n_improvements}\")\n",
    "            print(f\"  Eficiencia: {efficiency:.2f}\")\n",
    "            \n",
    "            # Verificar que los valores existan antes de acceder a ellos\n",
    "            if values:\n",
    "                print(f\"  Valor inicial: {values[0]:.4f}\")\n",
    "                print(f\"  Valor final: {values[-1]:.4f}\")\n",
    "                print(f\"  Mejor valor: {max(values):.4f}\")\n",
    "            \n",
    "            if efficiency > 0.1:\n",
    "                print(\"  ✅ La optimización muestra mejora progresiva (eficiente)\")\n",
    "            else:\n",
    "                print(\"  ⚠️ Baja tasa de mejora, posible ineficiencia\")\n",
    "                \n",
    "            # Verificar si el mejor valor proviene de trials recientes (sign de persistencia)\n",
    "            best_trial = study.best_trial\n",
    "            all_trials = sorted(study.trials, key=lambda t: t.datetime_start)\n",
    "            if all_trials and best_trial in all_trials[-int(len(all_trials)*0.3):]:\n",
    "                print(\"  ✅ El mejor resultado proviene de trials recientes (persistencia funciona)\")\n",
    "            else:\n",
    "                print(\"  ⚠️ El mejor resultado no es reciente\")\n",
    "                \n",
    "            # Verificar si hay convergencia en el espacio de parámetros\n",
    "            params_to_check = ['n_clusters', 'window_size', 'markup']\n",
    "            for param in params_to_check:\n",
    "                if param in study.best_params:\n",
    "                    recent_values = [t.params.get(param) for t in all_trials[-10:] if param in t.params]\n",
    "                    if recent_values:\n",
    "                        mean_val = np.mean(recent_values)\n",
    "                        std_val = np.std(recent_values)\n",
    "                        # Evitar división por cero\n",
    "                        cv = std_val / mean_val if mean_val != 0 else float('inf')\n",
    "                        \n",
    "                        if cv < 0.2:  # Coeficiente de variación bajo indica convergencia\n",
    "                            print(f\"  ✅ Parámetro {param} converge a {mean_val:.2f} ± {std_val:.2f}\")\n",
    "                        else:\n",
    "                            print(f\"  ⚠️ Parámetro {param} no muestra convergencia clara\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al verificar eficiencia: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = 'XAUUSD'\n",
    "    timeframe = 'H1'\n",
    "    n_trials_per_model = 50\n",
    "    model_range = range(0, 5)\n",
    "    \n",
    "    # Configurar ruta de la base de datos\n",
    "    db_dir = os.path.join(r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/', 'optuna_db')\n",
    "    db_path = os.path.join(db_dir, f'{symbol}_{timeframe}_study.db')\n",
    "    \n",
    "    # Limpiar estudios antiguos antes de comenzar\n",
    "    cleanup_old_studies(db_path, max_studies=20)\n",
    "    \n",
    "    # Para recopilar resultados globales de todos los modelos\n",
    "    all_results = {}\n",
    "    best_models = []\n",
    "    \n",
    "    for i in tqdm(model_range, desc=f\"Optimizando {symbol}/{timeframe}\", unit=\"modelo\"):\n",
    "        try:\n",
    "            model_results = optimize_and_export(symbol, timeframe, i, n_trials=n_trials_per_model)\n",
    "            best_models.append((i, model_results))\n",
    "            \n",
    "            # Añadir a resultados globales\n",
    "            all_results[f\"model_{i}\"] = {\n",
    "                \"success\": True,\n",
    "                \"forward_r2\": model_results[\"forward_r2\"],\n",
    "                \"backward_r2\": model_results[\"backward_r2\"],\n",
    "                \"combined_score\": model_results[\"combined_score\"]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            tqdm.write(f\"\\nError procesando modelo {i}: {str(e)}\")\n",
    "            tqdm.write(traceback.format_exc())\n",
    "            \n",
    "            all_results[f\"model_{i}\"] = {\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "            continue\n",
    "    \n",
    "    # Resumen final\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"RESUMEN DE OPTIMIZACIÓN {symbol}/{timeframe}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    successful_models = [info for model, info in all_results.items() if info.get(\"success\", False)]\n",
    "    print(f\"Modelos completados exitosamente: {len(successful_models)}/{len(model_range)}\")\n",
    "    \n",
    "    if successful_models:\n",
    "        # Calcular estadísticas globales\n",
    "        forward_scores = [info[\"forward_r2\"] for info in successful_models]\n",
    "        backward_scores = [info[\"backward_r2\"] for info in successful_models]\n",
    "        combined_scores = [info[\"combined_score\"] for info in successful_models]\n",
    "        \n",
    "        print(f\"\\nEstadísticas de rendimiento:\")\n",
    "        print(f\"  Forward R2 promedio: {np.mean(forward_scores):.4f} ± {np.std(forward_scores):.4f}\")\n",
    "        print(f\"  Backward R2 promedio: {np.mean(backward_scores):.4f} ± {np.std(backward_scores):.4f}\")\n",
    "        print(f\"  Puntuación combinada promedio: {np.mean(combined_scores):.4f} ± {np.std(combined_scores):.4f}\")\n",
    "        \n",
    "        # Identificar el mejor modelo global\n",
    "        best_model_idx = np.argmax(combined_scores)\n",
    "        best_model_key = list(all_results.keys())[best_model_idx]\n",
    "        best_info = all_results[best_model_key]\n",
    "        \n",
    "        print(f\"\\nMejor modelo global: {best_model_key}\")\n",
    "        print(f\"  Forward R2: {best_info['forward_r2']:.4f}\")\n",
    "        print(f\"  Backward R2: {best_info['backward_r2']:.4f}\")\n",
    "        print(f\"  Puntuación combinada: {best_info['combined_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nProceso de optimización completado.\")\n",
    "    \n",
    "    # Verificar la eficiencia y persistencia\n",
    "    print(\"\\n=== VERIFICACIÓN DE PERSISTENCIA Y EFICIENCIA ===\")\n",
    "    verify_optuna_efficiency(symbol, timeframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
