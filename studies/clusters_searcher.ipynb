{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5302a1a",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.labeling_lib import get_labels_one_direction\n",
    "from modules.labeling_lib import sliding_window_clustering\n",
    "from modules.tester_lib import tester_one_direction\n",
    "from modules.export_lib import export_model_to_ONNX\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cac365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener precios\n",
    "def get_prices(hyper_params) -> pd.DataFrame:\n",
    "    history_file = os.path.join(hyper_params[\"history_path\"], f\"{hyper_params['symbol']}_{hyper_params['timeframe']}.csv\")\n",
    "    p = pd.read_csv(history_file, sep=r\"\\s+\")\n",
    "    pFixed = pd.DataFrame(columns=['time', 'close'])\n",
    "    pFixed['time'] = p['<DATE>'] + ' ' + p['<TIME>']\n",
    "    pFixed['time'] = pd.to_datetime(pFixed['time'], format='mixed')\n",
    "    pFixed['close'] = p['<CLOSE>']\n",
    "    pFixed.set_index('time', inplace=True)\n",
    "    return pFixed.dropna()\n",
    "# Ingeniería de características\n",
    "def get_features(data: pd.DataFrame, hp):\n",
    "    out = pd.DataFrame(index=data.index)\n",
    "    for win in hp[\"periods\"]:\n",
    "        out[f\"{win}\"] = data['close'].rolling(win).std(ddof=1).shift(1)\n",
    "    for win in hp[\"periods_meta\"]:\n",
    "        out[f\"{win}_meta_feature\"]  = data['close'].rolling(win).std(ddof=1).shift(1)\n",
    "    out[\"close\"] = data[\"close\"]\n",
    "    display(out.dropna().head(1))\n",
    "    return out.dropna()\n",
    "    \n",
    "def test_model_one_direction(\n",
    "        dataset: pd.DataFrame,\n",
    "        result:  list,\n",
    "        forward: datetime,\n",
    "        backward: datetime,\n",
    "        markup:  float,\n",
    "        direction: str,\n",
    "        plt: bool = False):\n",
    "\n",
    "    pr_tst = dataset.copy()           # ahora usamos el dataset recibido\n",
    "    X = pr_tst.drop(columns=['close'])\n",
    "    X_meta = X.loc[:,  X.columns.str.contains('meta_feature')]\n",
    "    X      = X.loc[:, ~X.columns.str.contains('meta_feature')]\n",
    "\n",
    "    pr_tst['labels']      = result[0].predict_proba(X)[:,1]\n",
    "    pr_tst['meta_labels'] = result[1].predict_proba(X_meta)[:,1]\n",
    "\n",
    "    # Corrección aquí:\n",
    "    pr_tst[['labels', 'meta_labels']] = (pr_tst[['labels', 'meta_labels']] >= 0.5).astype(float)\n",
    "\n",
    "    return tester_one_direction(pr_tst, forward, backward, markup, direction, plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15736753",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e880b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_final_models(clustered: pd.DataFrame,\n",
    "                     meta: pd.DataFrame,\n",
    "                     oos_data: pd.DataFrame,\n",
    "                     hp: Dict[str, Any]) -> Tuple[float, Any, Any]:\n",
    "    \"\"\"Entrena modelo principal + meta‑modelo y evalúa en OOS.\n",
    "\n",
    "    Devuelve (R2, model, meta_model).\n",
    "    \"\"\"\n",
    "    # ---------- 1) main model ----------\n",
    "    X_main = clustered.drop(columns=['labels', *meta.columns[meta.columns.str.contains('_meta_feature')]])\n",
    "    y_main = clustered['labels'].astype('int16')\n",
    "\n",
    "    # ---------- 2) meta‑model ----------\n",
    "    X_meta = meta.loc[:, meta.columns.str.contains('_meta_feature')]\n",
    "    y_meta = meta['clusters'].astype('int16')\n",
    "    # 3) Split aleatorio (70/30)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(\n",
    "        X_main, y_main, train_size=0.7, shuffle=True)\n",
    "    train_X_m, test_X_m, train_y_m, test_y_m = train_test_split(\n",
    "        X_meta, y_meta, train_size=0.7, shuffle=True)\n",
    "    # debug\n",
    "    #common_index = X_main.index[0]\n",
    "    #display(X_main.loc[[common_index]])\n",
    "    #display(X_meta.loc[[common_index]])\n",
    "    # 4) Hiper‑parámetros CatBoost (con valores por defecto + overrides)\n",
    "    cat_main_params = dict(\n",
    "        iterations=hp.get('cat_iterations', 500),\n",
    "        depth=hp.get('cat_depth', 6),\n",
    "        learning_rate=hp.get('cat_learning_rate', 0.1),\n",
    "        l2_leaf_reg=hp.get('cat_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['Accuracy'],\n",
    "        eval_metric='Accuracy',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    #weights_main = compute_class_weight(class_weight='balanced', classes=np.unique(y_meta), y=y_meta)\n",
    "    #cat_main_params['class_weights'] = list(weights_main)\n",
    "    model = CatBoostClassifier(**cat_main_params)\n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y), early_stopping_rounds=25)\n",
    "\n",
    "    cat_meta_params = dict(\n",
    "        iterations=hp.get('cat_meta_iterations', 300),\n",
    "        depth=hp.get('cat_meta_depth', 5),\n",
    "        learning_rate=hp.get('cat_meta_learning_rate', 0.15),\n",
    "        l2_leaf_reg=hp.get('cat_meta_l2_leaf_reg', 3.0),\n",
    "        custom_loss=['F1'],\n",
    "        eval_metric='F1',\n",
    "        use_best_model=True,\n",
    "        verbose=False,\n",
    "        thread_count=-1,\n",
    "        task_type='CPU',\n",
    "    )\n",
    "    #weights_meta = compute_class_weight(class_weight='balanced', classes=np.unique(y_meta), y=y_meta)\n",
    "    #cat_meta_params['class_weights'] = list(weights_meta)\n",
    "    meta_model = CatBoostClassifier(**cat_meta_params)\n",
    "    meta_model.fit(train_X_m, train_y_m, eval_set=(test_X_m, test_y_m), early_stopping_rounds=15)\n",
    "\n",
    "    # 5) Evaluación en datos fuera de muestra\n",
    "    R2 = test_model_one_direction(\n",
    "        oos_data,\n",
    "        [model, meta_model],\n",
    "        hp['full forward'],\n",
    "        hp['forward'],\n",
    "        hp['markup'],\n",
    "        hp['direction'],\n",
    "        plt=False,\n",
    "    )\n",
    "    if math.isnan(R2):\n",
    "        R2 = -1.0\n",
    "    return R2, model, meta_model\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#      ─── FUNCIÓN OBJETIVO PARA OPTUNA ───\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def objective(trial: optuna.trial.Trial, base_hp: Dict[str, Any], study=None) -> float:\n",
    "    hp = base_hp.copy()\n",
    "\n",
    "    # µ··· Espacio de búsqueda ···µ\n",
    "    hp['n_clusters']   = trial.suggest_int('n_clusters', 5, 60, step=5)\n",
    "    hp['window_size']  = trial.suggest_int('window_size', 100, 500, step=50)\n",
    "    hp['label_min']  = trial.suggest_int('label_min', 1, 10)\n",
    "    hp['label_max']  = trial.suggest_int('label_max', hp['label_min']+1, 30)\n",
    "\n",
    "    # CatBoost (main)\n",
    "    hp['cat_iterations']      = trial.suggest_int('cat_iterations', 300, 800, step=100)\n",
    "    hp['cat_depth']           = trial.suggest_int('cat_depth', 4, 10)\n",
    "    hp['cat_learning_rate']   = trial.suggest_float('cat_learning_rate', 0.03, 0.3, log=True)\n",
    "    hp['cat_l2_leaf_reg']     = trial.suggest_float('cat_l2_leaf_reg', 1.0, 7.0)\n",
    "\n",
    "    # Dataset completo\n",
    "    full_ds = get_features(get_prices(hp), hp)\n",
    "    ds_train = full_ds[(full_ds.index > hp['backward']) & (full_ds.index < hp['forward'])]\n",
    "    ds_oos   = full_ds[(full_ds.index >= hp['forward']) & (full_ds.index < hp['full forward'])]\n",
    "\n",
    "    # Clustering con ventana deslizante\n",
    "    data = sliding_window_clustering(\n",
    "        ds_train,\n",
    "        n_clusters=hp['n_clusters'],\n",
    "        window_size=hp['window_size']\n",
    "    )\n",
    "\n",
    "    best_R2 = -math.inf\n",
    "    for clust in np.sort(data['clusters'].unique()):\n",
    "        clustered_data = data[data['clusters'] == clust].copy()\n",
    "        if len(clustered_data) < 500:\n",
    "            continue\n",
    "\n",
    "        clustered_data = get_labels_one_direction(\n",
    "            clustered_data,\n",
    "            markup    = hp['markup'],       # valor constante\n",
    "            min       = hp['label_min'],\n",
    "            max       = hp['label_max'],\n",
    "            direction = hp['direction'])\n",
    "\n",
    "        clustered_data = clustered_data.drop(['close', 'clusters'], axis=1)\n",
    "        meta_data = data.copy()\n",
    "        meta_data['clusters'] = (meta_data['clusters'] == clust).astype(int)\n",
    "\n",
    "        R2, model, meta_model = fit_final_models(\n",
    "            clustered_data,\n",
    "            meta_data.drop(['close'], axis=1),\n",
    "            ds_oos,\n",
    "            hp\n",
    "        )\n",
    "\n",
    "        if R2 < 1.0 and R2 > best_R2:\n",
    "            best_R2 = R2\n",
    "            best_pack = (model, meta_model)\n",
    "\n",
    "    # Guardamos modelos en los atributos del estudio (solo si se proporcionó)\n",
    "    if study is not None:\n",
    "        study.set_user_attr(\"best_model\", best_pack[0])\n",
    "        study.set_user_attr(\"best_meta_model\", best_pack[1])\n",
    "        study.set_user_attr(\"best_r2\", best_R2)\n",
    "\n",
    "    return best_R2\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#                 ─── PIPELINE DE OPTIMIZACIÓN + EXPORT ───\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def optimize_and_export(symbol: str = 'BTCUSDT', timeframe: str = 'H1', n_trials: int = 50):\n",
    "    \"\"\"Lanza Optuna, guarda el mejor modelo y lo exporta a ONNX.\"\"\"\n",
    "\n",
    "    common_file_folder = r\"/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/Common/Files/\"\n",
    "    mql5_files_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Files/'\n",
    "    mql5_include_folder = r'/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/6C3C6A11D1C3791DD4DBF45421BF8028/MQL5/Include/ajmtrz/include/Dmitrievsky'\n",
    "\n",
    "    base_hp: Dict[str, Any] = {\n",
    "        'symbol': symbol,\n",
    "        'timeframe': timeframe,\n",
    "        'models_export_path': mql5_files_folder,\n",
    "        'include_export_path': mql5_include_folder,\n",
    "        'history_path': common_file_folder,\n",
    "        'best_models': [],\n",
    "        'model_number': 0,\n",
    "        'markup': 0.20,\n",
    "        'label_min'  : 3,\n",
    "        'label_max'  : 15,\n",
    "        'direction': 'buy',\n",
    "        'n_clusters': 30,\n",
    "        'window_size': 350,\n",
    "        'periods': [i for i in range(5, 300, 30)][::-1],\n",
    "        'periods_meta': [5],\n",
    "        'backward': datetime(2020, 3, 26),\n",
    "        'forward': datetime(2024, 1, 1),\n",
    "        'full forward': datetime(2026, 1, 1),\n",
    "    }\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda t: objective(t, base_hp, study), n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "\n",
    "    print(\"\\n┌───────────────────────────────────────────────┐\")\n",
    "    print(\"│      MEJOR RESULTADO = {:.4f}                 │\".format(study.best_value))\n",
    "    print(\"└───────────────────────────────────────────────┘\\n\")\n",
    "    print(\"Parámetros óptimos:\\n\", study.best_params)\n",
    "\n",
    "    # Vuelve a entrenar con los mejores hiper‑parámetros y exporta\n",
    "    base_hp.update(study.best_params)\n",
    "    model      = study.user_attrs[\"best_model\"]\n",
    "    meta_model = study.user_attrs[\"best_meta_model\"]\n",
    "    best_r2    = study.user_attrs[\"best_r2\"]\n",
    "    base_hp.pop('best_models', None)\n",
    "    print(\"Exportando modelos ONNX… R2 = {:.4f}\".format(best_r2))\n",
    "    export_model_to_ONNX(best_models=[model, meta_model], **base_hp)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimize_and_export('XAUUSD', 'H1', n_trials=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
