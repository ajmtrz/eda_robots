{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cupy as cp\n",
    "#import cudf\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\n",
    "from onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(tester_files_folder):\n",
    "    # Preparación de los datos de compra\n",
    "    df_buy = cudf.read_csv(os.path.join(tester_files_folder, \"buy_training_dataset.csv\"))\n",
    "    if df_buy.isna().any().any():\n",
    "        df_buy = df_buy.dropna()\n",
    "    df_buy = df_buy.sample(frac=1).reset_index(drop=True)\n",
    "    X_buy_train = df_buy.drop(columns='target')\n",
    "    y_buy_train = df_buy['target']\n",
    "    # Preparación de los datos de venta\n",
    "    df_sell = cudf.read_csv(os.path.join(tester_files_folder, \"sell_training_dataset.csv\"))\n",
    "    if df_sell.isna().any().any():\n",
    "        df_sell = df_sell.dropna()\n",
    "    df_sell = df_sell.sample(frac=1).reset_index(drop=True)\n",
    "    X_sell_train = df_sell.drop(columns='target')\n",
    "    y_sell_train = df_sell['target']\n",
    "    return X_buy_train, y_buy_train, X_sell_train, y_sell_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_buy_train, y_buy_train, X_sell_train, y_sell_train = load_dataset(r\"/mnt/c/Users/Administrador/AppData/Roaming/MetaQuotes/Terminal/Common/Files/\")\n",
    "print(f\"Buy -> Trades: {X_buy_train.shape[0]} Features: {X_buy_train.shape[1]}\")\n",
    "print(f\"Sell -> Trades: {X_sell_train.shape[0]} Features: {X_sell_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo genético para encontrar los mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_chromosome(chromosome, param_grid):\n",
    "    param_values = {}\n",
    "    for i, key in enumerate(param_grid.keys()):\n",
    "        gene = chromosome[i]\n",
    "        param_info = param_grid[key]\n",
    "        low = param_info['low']\n",
    "        high = param_info['high']\n",
    "        if param_info['type'] == 'int':\n",
    "            value = int(cp.round(gene * (high - low) + low))\n",
    "        elif param_info['type'] == 'float':\n",
    "            value = gene * (high - low) + low\n",
    "        param_values[key] = value\n",
    "    return param_values\n",
    "\n",
    "def initialize_population(pop_size, chromosome_length):\n",
    "    population = cp.random.uniform(low=0.0, high=1.0, size=(pop_size, chromosome_length))\n",
    "    return population\n",
    "\n",
    "def evaluate_population(population, X_train, y_train, cv, param_grid):\n",
    "    fitnesses = []\n",
    "    for chromosome in population:\n",
    "        params = decode_chromosome(chromosome, param_grid)\n",
    "        scores = []\n",
    "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            model = xgb.XGBClassifier(\n",
    "                tree_method='gpu_hist',\n",
    "                predictor='gpu_predictor',\n",
    "                use_label_encoder=False,\n",
    "                verbosity=0,\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_tr, y_tr)\n",
    "            y_pred = model.predict(X_val)\n",
    "            score = accuracy_score(y_val, y_pred)\n",
    "            scores.append(score)\n",
    "        fitness = cp.mean(cp.array(scores))\n",
    "        fitnesses.append(fitness)\n",
    "    return cp.array(fitnesses)\n",
    "\n",
    "def select_parents(population, fitnesses, tournament_size=2):\n",
    "    selected = []\n",
    "    for _ in range(len(population)):\n",
    "        indices = cp.random.randint(0, len(population), size=tournament_size)\n",
    "        best_idx = indices[cp.argmax(fitnesses[indices])]\n",
    "        selected.append(population[best_idx])\n",
    "    return cp.vstack(selected)\n",
    "\n",
    "def crossover(parents, crossover_rate):\n",
    "    offspring = []\n",
    "    for i in range(0, len(parents), 2):\n",
    "        parent1 = parents[i].copy()\n",
    "        parent2 = parents[(i+1) % len(parents)].copy()\n",
    "        if cp.random.rand() < crossover_rate:\n",
    "            point = cp.random.randint(1, len(parent1))\n",
    "            child1 = cp.concatenate((parent1[:point], parent2[point:]))\n",
    "            child2 = cp.concatenate((parent2[:point], parent1[point:]))\n",
    "            offspring.append(child1)\n",
    "            offspring.append(child2)\n",
    "        else:\n",
    "            offspring.append(parent1)\n",
    "            offspring.append(parent2)\n",
    "    return cp.vstack(offspring)\n",
    "\n",
    "def mutate(offspring, mutation_rate, mutation_scale=0.1):\n",
    "    for chromosome in offspring:\n",
    "        if cp.random.rand() < mutation_rate:\n",
    "            gene_idx = cp.random.randint(0, len(chromosome))\n",
    "            mutation = cp.random.normal(0, mutation_scale)\n",
    "            chromosome[gene_idx] += mutation\n",
    "            chromosome[gene_idx] = cp.clip(chromosome[gene_idx], 0.0, 1.0)\n",
    "    return offspring\n",
    "\n",
    "def genetic_algorithm(\n",
    "    X_train, y_train, param_grid, pop_size=20, generations=10, early_stopping_rounds=1,\n",
    "    crossover_initial=0.1, crossover_end=0.9,\n",
    "    mutation_initial=0.9, mutation_end=0.1,\n",
    "    elitism=True, elite_size=3,\n",
    "    tournament_size=5\n",
    "):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    chromosome_length = len(param_grid)\n",
    "    population = initialize_population(pop_size, chromosome_length)\n",
    "    best_overall_fitness = -cp.inf\n",
    "    best_overall_chromosome = None\n",
    "    no_improvement_generations = 0\n",
    "\n",
    "    for generation in range(generations):\n",
    "        print(f\"Generación [{generation+1}]\")\n",
    "        crossover_rate = crossover_initial * ((crossover_end / crossover_initial) ** (generation / generations))\n",
    "        mutation_rate = mutation_initial * ((mutation_end / mutation_initial) ** (generation / generations))\n",
    "        print(f\"Probabilidad de cruce en generación [{generation+1}]: {crossover_rate:.4f}, Probabilidad de mutación: {mutation_rate:.4f}\")\n",
    "        fitnesses = evaluate_population(population, X_train, y_train, cv, param_grid)\n",
    "        current_best_fitness = cp.max(fitnesses)\n",
    "        print(f\"Mejor fitness en generación [{generation+1}]: {current_best_fitness}\")\n",
    "        if current_best_fitness > best_overall_fitness:\n",
    "            best_overall_fitness = current_best_fitness\n",
    "            best_idx = cp.argmax(fitnesses)\n",
    "            best_overall_chromosome = population[best_idx]\n",
    "            no_improvement_generations = 0\n",
    "        else:\n",
    "            no_improvement_generations += 1\n",
    "        if no_improvement_generations >= early_stopping_rounds:\n",
    "            print(f\"No hubo mejora en el fitness por {early_stopping_rounds} generaciones consecutivas. Deteniendo el algoritmo.\")\n",
    "            break\n",
    "        if elitism:\n",
    "            sorted_indices = cp.argsort(fitnesses)[::-1]\n",
    "            elites = population[sorted_indices[:elite_size]]\n",
    "        else:\n",
    "            elites = None\n",
    "        parents = select_parents(population, fitnesses, tournament_size=tournament_size)\n",
    "        offspring = crossover(parents, crossover_rate=crossover_rate)\n",
    "        population = mutate(offspring, mutation_rate=mutation_rate)\n",
    "        if elitism:\n",
    "            population = cp.vstack((elites, population))\n",
    "            if len(population) > pop_size:\n",
    "                population = population[:pop_size]\n",
    "                \n",
    "    best_params = decode_chromosome(best_overall_chromosome, param_grid)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir param_grid con rangos\n",
    "param_grid = {\n",
    "    'n_estimators': {'type': 'int', 'low': 50, 'high': 500},\n",
    "    'max_depth': {'type': 'int', 'low': 3, 'high': 10},\n",
    "    'learning_rate': {'type': 'float', 'low': 0.01, 'high': 0.3},\n",
    "    'subsample': {'type': 'float', 'low': 0.6, 'high': 1.0},\n",
    "    'colsample_bytree': {'type': 'float', 'low': 0.6, 'high': 1.0},\n",
    "    'gamma': {'type': 'float', 'low': 0.0, 'high': 0.5},\n",
    "    'min_child_weight': {'type': 'int', 'low': 1, 'high': 10},\n",
    "    'reg_alpha': {'type': 'float', 'low': 0.0, 'high': 1.0},\n",
    "    'reg_lambda': {'type': 'float', 'low': 0.0, 'high': 1.0}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos simultáneamente\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # enviar tareas de entrenamiento\n",
    "    best_buy_params = executor.submit(genetic_algorithm,\n",
    "        X_buy_train, y_buy_train, param_grid,\n",
    "        pop_size=50,\n",
    "        generations=100,\n",
    "        early_stopping_rounds=5,\n",
    "        crossover_initial=0.1,\n",
    "        crossover_end=0.9,\n",
    "        mutation_initial=0.9,\n",
    "        mutation_end=0.1,\n",
    "        elitism=True,\n",
    "        elite_size=2,\n",
    "        tournament_size=5\n",
    "    )\n",
    "    best_sell_params = executor.submit(genetic_algorithm,\n",
    "        X_sell_train, y_sell_train, param_grid,\n",
    "        pop_size=50,\n",
    "        generations=100,\n",
    "        early_stopping_rounds=5,\n",
    "        crossover_initial=0.1,\n",
    "        crossover_end=0.9,\n",
    "        mutation_initial=0.9,\n",
    "        mutation_end=0.1,\n",
    "        elitism=True,\n",
    "        elite_size=2,\n",
    "        tournament_size=5\n",
    "    )\n",
    "    # esperar a que todas las tareas terminen\n",
    "    print(\"Esperando que las tareas finalicen...\")\n",
    "    futures = [best_buy_params, best_sell_params]\n",
    "    wait(futures)\n",
    "    print(\"¡Todas las tareas han terminado!\")\n",
    "    # Obtener resultados una vez que ambas tareas han terminado\n",
    "    model_buy_params = best_buy_params.result()\n",
    "    model_sell_params = best_sell_params.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo de compra con los mejores hiperparámetros\n",
    "model_buy = xgb.XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    predictor='gpu_predictor',\n",
    "    use_label_encoder=False,\n",
    "    verbosity=0,\n",
    "    **model_buy_params\n",
    ")\n",
    "model_buy.fit(X_buy_train, y_buy_train)\n",
    "\n",
    "# Entrenar el modelo de venta con los mejores hiperparámetros\n",
    "model_sell = xgb.XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    predictor='gpu_predictor',\n",
    "    use_label_encoder=False,\n",
    "    verbosity=0,\n",
    "    **model_sell_params\n",
    ")\n",
    "model_sell.fit(X_sell_train, y_sell_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar modelos a formato ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_onnx_models(mql5_files_folder):\n",
    "    try:\n",
    "        update_registered_converter(\n",
    "            xgb.XGBClassifier,\n",
    "            \"XGBClassifier\",\n",
    "            calculate_linear_classifier_output_shapes,\n",
    "            convert_xgboost,\n",
    "            options={'nocl': [True, False], 'zipmap': [True, False, 'columns']}\n",
    "        )\n",
    "        model_buy_onnx = convert_sklearn(\n",
    "            model_buy,\n",
    "            'pipeline_buy_xgboost',\n",
    "            [('input', FloatTensorType([None, X_buy_train.shape[1]]))],\n",
    "            target_opset={'': 12, 'ai.onnx.ml': 2}\n",
    "        )\n",
    "        model_sell_onnx = convert_sklearn(\n",
    "            model_sell,\n",
    "            'pipeline_sell_xgboost',\n",
    "            [('input', FloatTensorType([None, X_buy_train.shape[1]]))],\n",
    "            target_opset={'': 12, 'ai.onnx.ml': 2}\n",
    "        )\n",
    "        with open(os.path.join(mql5_files_folder, \"model_buy.onnx\"), 'wb') as f:\n",
    "            f.write(model_buy_onnx.SerializeToString())\n",
    "        with open(os.path.join(mql5_files_folder, \"model_sell.onnx\"), 'wb') as f:\n",
    "            f.write(model_sell_onnx.SerializeToString())\n",
    "    except Exception as e:\n",
    "        print(f\"Error en exportar los modelos: {e}\")\n",
    "        raise\n",
    "    print(\"Modelos ONNX exportados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_onnx_models(r'C:\\Users\\Administrador\\AppData\\Roaming\\MetaQuotes\\Terminal\\6C3C6A11D1C3791DD4DBF45421BF8028\\MQL5\\Files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
