{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9738488,"sourceType":"datasetVersion","datasetId":5960624}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importar librerías","metadata":{}},{"cell_type":"code","source":"!pip -q uninstall -y tensorflow-cloud tensorflow tensorflow-transform tensorflow-serving-api witwidget apache-beam google-cloud-aiplatform google-cloud-automl kfp\n!pip -q install skl2onnx onnxmltools","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cupy as cp\nimport cudf\nfrom cuml.metrics import accuracy_score\nfrom cuml.model_selection import StratifiedKFold\nimport xgboost as xgb\nfrom concurrent.futures import ThreadPoolExecutor, wait\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx import convert_sklearn, update_registered_converter\nfrom skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\nfrom onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cargar y preparar datos","metadata":{}},{"cell_type":"code","source":"def load_dataset(tester_files_folder):\n    # Preparación de los datos de compra\n    df_buy = cudf.read_csv(os.path.join(tester_files_folder, \"buy_training_dataset.csv\"))\n    if df_buy.isna().any().any():\n        df_buy = df_buy.dropna()\n    df_buy = df_buy.sample(frac=1).reset_index(drop=True)\n    X_buy_train = df_buy.drop(columns='target').to_cupy()\n    y_buy_train = df_buy['target'].to_cupy()\n    # Preparación de los datos de venta\n    df_sell = cudf.read_csv(os.path.join(tester_files_folder, \"sell_training_dataset.csv\"))\n    if df_sell.isna().any().any():\n        df_sell = df_sell.dropna()\n    df_sell = df_sell.sample(frac=1).reset_index(drop=True)\n    X_sell_train = df_sell.drop(columns='target').to_cupy()\n    y_sell_train = df_sell['target'].to_cupy()\n    return X_buy_train, y_buy_train, X_sell_train, y_sell_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_buy_train, y_buy_train, X_sell_train, y_sell_train = load_dataset(r\"/kaggle/input/smarsi-training/\")\nprint(f\"Buy  -> Trades: {X_buy_train.shape[0]} | Features: {X_buy_train.shape[1]}\")\nprint(f\"Sell -> Trades: {X_sell_train.shape[0]} | Features: {X_sell_train.shape[1]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Algoritmo genético para encontrar los mejores hiperparámetros","metadata":{}},{"cell_type":"code","source":"def decode_chromosome(chromosome, param_grid):\n    param_values = {}\n    for i, key in enumerate(param_grid.keys()):\n        gene = chromosome[i]\n        param_info = param_grid[key]\n        low = param_info['low']\n        high = param_info['high']\n        if param_info['type'] == 'int':\n            value = int(cp.round(gene * (high - low) + low))\n        elif param_info['type'] == 'float':\n            value = gene * (high - low) + low\n        param_values[key] = value\n    return param_values\n\ndef initialize_population(pop_size, chromosome_length):\n    population = cp.random.uniform(low=0.0, high=1.0, size=(pop_size, chromosome_length))\n    return population\n\ndef evaluate_population(population, X_train, y_train, cv, param_grid):\n    fitnesses = []\n    for chromosome in population:\n        params = decode_chromosome(chromosome, param_grid)\n        scores = []\n        for train_idx, val_idx in cv.split(X_train, y_train):\n            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n            \n            model = xgb.XGBClassifier(\n                tree_method='gpu_hist',\n                predictor='gpu_predictor',\n                use_label_encoder=False,\n                verbosity=0,\n                **params\n            )\n            model.fit(X_tr, y_tr)\n            y_pred = model.predict(X_val)\n            score = accuracy_score(y_val, y_pred)\n            scores.append(score)\n        fitness = cp.mean(cp.array(scores))\n        fitnesses.append(fitness)\n    return cp.array(fitnesses)\n\ndef select_parents(population, fitnesses, tournament_size=2):\n    selected = []\n    for _ in range(len(population)):\n        indices = cp.random.randint(0, len(population), size=tournament_size)\n        best_idx = indices[cp.argmax(fitnesses[indices])]\n        selected.append(population[best_idx])\n    return cp.vstack(selected)\n\ndef crossover(parents, crossover_rate):\n    offspring = []\n    for i in range(0, len(parents), 2):\n        parent1 = parents[i].copy()\n        parent2 = parents[(i+1) % len(parents)].copy()\n        if cp.random.rand() < crossover_rate:\n            point = cp.random.randint(1, len(parent1))\n            child1 = cp.concatenate((parent1[:point], parent2[point:]))\n            child2 = cp.concatenate((parent2[:point], parent1[point:]))\n            offspring.append(child1)\n            offspring.append(child2)\n        else:\n            offspring.append(parent1)\n            offspring.append(parent2)\n    return cp.vstack(offspring)\n\ndef mutate(offspring, mutation_rate, mutation_scale=0.1):\n    for chromosome in offspring:\n        if cp.random.rand() < mutation_rate:\n            gene_idx = cp.random.randint(0, len(chromosome))\n            mutation = cp.random.normal(0, mutation_scale)\n            chromosome[gene_idx] += mutation\n            chromosome[gene_idx] = cp.clip(chromosome[gene_idx], 0.0, 1.0)\n    return offspring\nimport cupy as cp\n\ndef generate_random_individuals(n_random, param_grid):\n    chromosome_length = len(param_grid)\n    random_chromosomes = cp.empty((n_random, chromosome_length), dtype=cp.float32)\n    \n    for i, key in enumerate(param_grid.keys()):\n        grid = param_grid[key]\n        low = grid['low']\n        high = grid['high']\n        \n        if grid['type'] == 'int':\n            sampled = cp.random.randint(low, high + 1, size=n_random)\n            normalized = (sampled - low) / (high - low)\n            random_chromosomes[:, i] = normalized.astype(cp.float32)\n        \n        elif grid['type'] == 'float':\n            sampled = cp.random.uniform(low, high, size=n_random)\n            normalized = (sampled - low) / (high - low)\n            random_chromosomes[:, i] = normalized.astype(cp.float32)\n        \n        else:\n            raise ValueError(f\"Tipo de parámetro no soportado: {grid['type']}\")\n    \n    return random_chromosomes\n\ndef genetic_algorithm(\n    X_train, y_train, param_grid, model_type, pop_size=20, generations=10, early_stopping_rounds=1,\n    crossover_initial=0.1, crossover_end=0.9,\n    mutation_initial=0.9, mutation_end=0.1,\n    elitism=True, elite_size=3,\n    tournament_size=5, n_random=5\n):\n    cv = StratifiedKFold(n_splits=5, shuffle=True)\n    chromosome_length = len(param_grid)\n    population = initialize_population(pop_size, chromosome_length)\n    best_overall_fitness = -cp.inf\n    best_overall_chromosome = None\n    no_improvement_generations = 0\n\n    for generation in range(generations):\n        crossover_rate = crossover_initial * ((crossover_end / crossover_initial) ** (generation / generations))\n        mutation_rate = mutation_initial * ((mutation_end / mutation_initial) ** (generation / generations))\n        print(f\"Probabilidad de cruce en generación [{generation+1}] [{model_type}]: {crossover_rate:.4f}, Probabilidad de mutación: {mutation_rate:.4f}\")\n        fitnesses = evaluate_population(population, X_train, y_train, cv, param_grid)\n        current_best_fitness = cp.max(fitnesses)\n        print(f\"Mejor fitness en generación [{generation+1}] [{model_type}]: {current_best_fitness}\")\n        if current_best_fitness > best_overall_fitness:\n            best_overall_fitness = current_best_fitness\n            best_idx = cp.argmax(fitnesses)\n            best_overall_chromosome = population[best_idx]\n            no_improvement_generations = 0\n        else:\n            no_improvement_generations += 1\n        if no_improvement_generations >= early_stopping_rounds:\n            print(f\"No hubo mejora en el fitness por {early_stopping_rounds} generaciones consecutivas. Deteniendo el algoritmo [{model_type}].\")\n            break\n\n        if elitism:\n            sorted_indices = cp.argsort(fitnesses)[::-1]\n            elites = population[sorted_indices[:elite_size]]\n        else:\n            elites = None\n\n        parents = select_parents(population, fitnesses, tournament_size=tournament_size)\n        offspring = crossover(parents, crossover_rate=crossover_rate)\n        offspring = mutate(offspring, mutation_rate=mutation_rate)        \n        random_individuals = generate_random_individuals(n_random, param_grid)\n        offspring = cp.vstack((offspring, random_individuals))\n\n        if elitism:\n            population = cp.vstack((elites, offspring))\n        else:\n            population = offspring\n\n        if len(population) > pop_size:\n            fitnesses = evaluate_population(population, X_train, y_train, cv, param_grid)\n            sorted_indices = cp.argsort(fitnesses)[::-1]\n            population = population[sorted_indices[:pop_size]]\n\n    best_params = decode_chromosome(best_overall_chromosome, param_grid)\n    return best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Definir param_grid con rangos\nparam_grid = {\n    'n_estimators': {'type': 'int', 'low': 50, 'high': 500},\n    'max_depth': {'type': 'int', 'low': 3, 'high': 10},\n    'learning_rate': {'type': 'float', 'low': 0.01, 'high': 0.3},\n    'subsample': {'type': 'float', 'low': 0.6, 'high': 1.0},\n    'colsample_bytree': {'type': 'float', 'low': 0.6, 'high': 1.0},\n    'gamma': {'type': 'float', 'low': 0.0, 'high': 0.5},\n    'min_child_weight': {'type': 'int', 'low': 1, 'high': 10},\n    'reg_alpha': {'type': 'float', 'low': 0.0, 'high': 1.0},\n    'reg_lambda': {'type': 'float', 'low': 0.0, 'high': 1.0}\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Entrenar modelos simultáneamente\nwith ThreadPoolExecutor(max_workers=2) as executor:\n    # enviar tareas de entrenamiento\n    best_buy_params = executor.submit(genetic_algorithm,\n        X_buy_train, y_buy_train, param_grid,\n        model_type=\"Buy\",                      \n        pop_size=50,\n        generations=100,\n        early_stopping_rounds=5,\n        crossover_initial=0.1,\n        crossover_end=0.9,\n        mutation_initial=0.9,\n        mutation_end=0.1,\n        elitism=True,\n        elite_size=2,\n        tournament_size=5,\n        n_random=5\n    )\n    best_sell_params = executor.submit(genetic_algorithm,\n        X_sell_train, y_sell_train, param_grid,\n        model_type=\"Sell\",\n        pop_size=50,\n        generations=100,\n        early_stopping_rounds=5,\n        crossover_initial=0.1,\n        crossover_end=0.9,\n        mutation_initial=0.9,\n        mutation_end=0.1,\n        elitism=True,\n        elite_size=2,\n        tournament_size=5,\n        n_random=5\n    )\n    # esperar a que todas las tareas terminen\n    print(\"Esperando que las tareas finalicen...\")\n    futures = [best_buy_params, best_sell_params]\n    wait(futures)\n    print(\"¡Todas las tareas han terminado!\")\n    # Obtener resultados una vez que ambas tareas han terminado\n    model_buy_params = best_buy_params.result()\n    model_sell_params = best_sell_params.result()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Entrenar los modelos","metadata":{}},{"cell_type":"code","source":"def train_models(X_buy_train, X_sell_train, y_buy_train, y_sell_train):\n    # Entrenar el modelo de compra con los mejores hiperparámetros\n    model_buy = xgb.XGBClassifier(\n        tree_method='gpu_hist',\n        predictor='gpu_predictor',\n        use_label_encoder=False,\n        verbosity=0,\n        **model_buy_params\n    )\n    model_buy.fit(X_buy_train, y_buy_train)\n\n    # Entrenar el modelo de venta con los mejores hiperparámetros\n    model_sell = xgb.XGBClassifier(\n        tree_method='gpu_hist',\n        predictor='gpu_predictor',\n        use_label_encoder=False,\n        verbosity=0,\n        **model_sell_params\n    )\n    model_sell.fit(X_sell_train, y_sell_train)\n    \n    return(model_buy, model_sell)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train models\nmodel_buy, model_sell = train_models(X_buy_train, X_sell_train, y_buy_train, y_sell_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exportar modelos a formato ONNX","metadata":{}},{"cell_type":"code","source":"def save_onnx_models(mql5_files_folder):\n    try:\n        update_registered_converter(\n            xgb.XGBClassifier,\n            \"XGBClassifier\",\n            calculate_linear_classifier_output_shapes,\n            convert_xgboost,\n            options={'nocl': [True, False], 'zipmap': [True, False, 'columns']}\n        )\n        model_buy_onnx = convert_sklearn(\n            model_buy,\n            'pipeline_buy_xgboost',\n            [('input', FloatTensorType([None, X_buy_train.shape[1]]))],\n            target_opset={'': 12, 'ai.onnx.ml': 2}\n        )\n        model_sell_onnx = convert_sklearn(\n            model_sell,\n            'pipeline_sell_xgboost',\n            [('input', FloatTensorType([None, X_buy_train.shape[1]]))],\n            target_opset={'': 12, 'ai.onnx.ml': 2}\n        )\n        with open(os.path.join(mql5_files_folder, \"model_buy.onnx\"), 'wb') as f:\n            f.write(model_buy_onnx.SerializeToString())\n        with open(os.path.join(mql5_files_folder, \"model_sell.onnx\"), 'wb') as f:\n            f.write(model_sell_onnx.SerializeToString())\n    except Exception as e:\n        print(f\"Error en exportar los modelos: {e}\")\n        raise\n    print(\"Modelos ONNX exportados correctamente\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exportar modelos\nsave_onnx_models(r'/kaggle/working/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}