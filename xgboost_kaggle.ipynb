{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9772014,"sourceType":"datasetVersion","datasetId":5974416}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importar librerías","metadata":{}},{"cell_type":"code","source":"!pip -q uninstall -y tensorflow-cloud tensorflow tensorflow-transform tensorflow-serving-api witwidget apache-beam google-cloud-aiplatform google-cloud-automl kfp\n!pip -q install skl2onnx onnxmltools","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:02:40.369002Z","iopub.execute_input":"2024-10-31T13:02:40.369824Z","iopub.status.idle":"2024-10-31T13:02:55.074127Z","shell.execute_reply.started":"2024-10-31T13:02:40.369774Z","shell.execute_reply":"2024-10-31T13:02:55.072876Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping tensorflow-cloud as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping tensorflow-transform as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping tensorflow-serving-api as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping witwidget as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping apache-beam as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping google-cloud-aiplatform as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping google-cloud-automl as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport glob\nimport copy\nimport cupy as cp\nimport cudf\nfrom cuml.metrics import accuracy_score\nfrom cuml.model_selection import StratifiedKFold\nfrom cuml.preprocessing import StandardScaler\nfrom cuml.decomposition import PCA\nimport xgboost as xgb\nfrom cuml.pipeline import Pipeline\nfrom concurrent.futures import ThreadPoolExecutor, wait\nfrom skl2onnx.common.data_types import FloatTensorType\nfrom skl2onnx import convert_sklearn, update_registered_converter\nfrom skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes\nfrom onnxmltools.convert.xgboost.operator_converters.XGBoost import convert_xgboost\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:02:55.076709Z","iopub.execute_input":"2024-10-31T13:02:55.077477Z","iopub.status.idle":"2024-10-31T13:03:00.166575Z","shell.execute_reply.started":"2024-10-31T13:02:55.077425Z","shell.execute_reply":"2024-10-31T13:03:00.165496Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Cargar y preparar datos","metadata":{}},{"cell_type":"code","source":"def create_training_dataset(df, trade_type):\n    df = df.drop_duplicates()\n    # Filtrar las operaciones del tipo especificado y con profit != 0\n    df_trade = df[(df['type'] == trade_type) & (df['profit'] != 0)].copy()\n    # Separar en ganadoras y perdedoras\n    df_winning = df_trade[df_trade['profit'] > 0]\n    df_losing = df_trade[df_trade['profit'] < 0]\n    n_winning = len(df_winning)\n    n_losing = len(df_losing)\n    print(f\"Tipo de operación: {'Buy' if trade_type == 1 else 'Sell'}\")\n    print(f\"Total Ganadoras: {n_winning}\")\n    print(f\"Total Perdedoras: {n_losing}\")\n    # Verificar que hay suficientes datos\n    if n_winning == 0 or n_losing == 0:\n        print(f\"No hay suficientes datos para {'compras' if trade_type == 1 else 'ventas'} para entrenar el modelo.\")\n        return False\n    # Equilibrar las clases\n    if n_winning <= n_losing:\n        n_samples_per_class = n_winning\n        # Seleccionar todas las ganadoras\n        selected_winning = df_winning.copy()\n        # Ordenar las perdedoras por pérdida de mayor a menor (menor profit a mayor)\n        df_losing_sorted = df_losing.sort_values(by='profit', ascending=True)\n        # Seleccionar las perdedoras con mayor pérdida\n        selected_losing = df_losing_sorted.head(n_samples_per_class)\n    else:\n        n_samples_per_class = n_losing\n        # Seleccionar todas las perdedoras\n        selected_losing = df_losing.copy()\n        # Ordenar las ganadoras por profit de mayor a menor\n        df_winning_sorted = df_winning.sort_values(by='profit', ascending=False)\n        # Seleccionar las ganadoras con mayor profit\n        selected_winning = df_winning_sorted.head(n_samples_per_class)\n    print(f\"Se seleccionarán {n_samples_per_class} muestras por clase.\")\n    # Combinar las muestras seleccionadas\n    df_training = cudf.concat([selected_winning, selected_losing], ignore_index=True)\n    # Añadir la columna 'Target' basada en el profit\n    df_training['target'] = df_training['profit'].apply(lambda x: 1 if x > 0 else 0)\n    # Seleccionar las columnas necesarias (todas menos las dos últimas para el conjunto principal,\n    # y todas las columnas de los subconjuntos excepto la última)\n    # Suponiendo que las dos últimas columnas en el conjunto principal son 'type' y 'profit'\n    feature_columns = df.columns[:-2]\n    df_training = df_training[feature_columns.tolist() + ['target']]\n    # Mezclar los datos\n    df_training = df_training.sample(frac=1).reset_index(drop=True)\n    # Eliminar posibles missings\n    if(df_training.isna().values.any()):\n        df_training=df_training.dropna()\n    # retunr df\n    return df_training","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:00.167870Z","iopub.execute_input":"2024-10-31T13:03:00.168426Z","iopub.status.idle":"2024-10-31T13:03:00.181201Z","shell.execute_reply.started":"2024-10-31T13:03:00.168376Z","shell.execute_reply":"2024-10-31T13:03:00.180266Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Cargar, limpiar y preparar datasets\ndef load_dataset(df):\n    # Preparación de los datos de compra\n    df_buy = create_training_dataset(df, trade_type=1)\n    X_buy_train = df_buy.drop(columns='target')\n    y_buy_train = df_buy['target']\n    # Preparación de los datos de venta\n    df_sell = create_training_dataset(df, trade_type=-1)\n    X_sell_train = df_sell.drop(columns='target')\n    y_sell_train = df_sell['target']\n    return X_buy_train.to_cupy(), y_buy_train.to_cupy(), X_sell_train.to_cupy(), y_sell_train.to_cupy()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:00.184017Z","iopub.execute_input":"2024-10-31T13:03:00.184399Z","iopub.status.idle":"2024-10-31T13:03:00.203896Z","shell.execute_reply.started":"2024-10-31T13:03:00.184365Z","shell.execute_reply":"2024-10-31T13:03:00.202816Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Carga\nfile_folder = r\"/kaggle/input/training-datasets/\"\nfile_pattern = os.path.join(file_folder, 'training_dataset_*.csv')\ndf_file_path = glob.glob(file_pattern)\ndf = cudf.read_csv(df_file_path[0])\n# Split\nX_buy_train, y_buy_train, X_sell_train, y_sell_train = load_dataset(df)\n# num features\nn_features = X_buy_train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:00.205268Z","iopub.execute_input":"2024-10-31T13:03:00.205678Z","iopub.status.idle":"2024-10-31T13:03:01.960122Z","shell.execute_reply.started":"2024-10-31T13:03:00.205643Z","shell.execute_reply":"2024-10-31T13:03:01.958898Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Tipo de operación: Buy\nTotal Ganadoras: 3045\nTotal Perdedoras: 2511\nSe seleccionarán 2511 muestras por clase.\nTipo de operación: Sell\nTotal Ganadoras: 2798\nTotal Perdedoras: 2182\nSe seleccionarán 2182 muestras por clase.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Algoritmo genético para encontrar los mejores hiperparámetros","metadata":{}},{"cell_type":"code","source":"class GeneticAlgorithmCV:\n    def __init__(\n        self,\n        estimator,\n        param_grid,\n        cv=None,\n        scoring=None,\n        pop_size=50,\n        generations=15,\n        early_stopping_rounds=1,\n        crossover_initial=0.1,\n        crossover_end=0.9,\n        mutation_initial=0.9,\n        mutation_end=0.1,\n        elitism=True,\n        elite_size=5,\n        tournament_size=3,\n        n_random=10,\n        verbose=False\n    ):\n        self.estimator = estimator\n        self.param_grid = param_grid\n        self.cv = cv\n        self.scoring = scoring\n        self.pop_size = pop_size\n        self.generations = generations\n        self.early_stopping_rounds = early_stopping_rounds\n        self.crossover_initial = crossover_initial\n        self.crossover_end = crossover_end\n        self.mutation_initial = mutation_initial\n        self.mutation_end = mutation_end\n        self.elitism = elitism\n        self.elite_size = elite_size\n        self.tournament_size = tournament_size\n        self.n_random = n_random\n        self.verbose = verbose\n        self.best_params_ = None\n        self.best_score_ = None\n\n    def decode_chromosome(self, chromosome):\n        param_values = {}\n        for i, key in enumerate(self.param_grid.keys()):\n            gene = chromosome[i]\n            param_info = self.param_grid[key]\n            low = param_info['low']\n            high = param_info['high']\n            if param_info['type'] == 'int':\n                value = int(cp.round(gene * (high - low) + low))\n            elif param_info['type'] == 'float':\n                value = gene * (high - low) + low\n            param_values[key] = value\n        return param_values\n\n    def initialize_population(self):\n        chromosome_length = len(self.param_grid)\n        population = cp.random.uniform(low=0.0, high=1.0, size=(self.pop_size, chromosome_length))\n        return population\n\n    def evaluate_population(self, population, X_train, y_train):\n        fitnesses = []\n        for chromosome in population:\n            params = self.decode_chromosome(chromosome)\n            scores = []\n            for train_idx, val_idx in self.cv.split(X_train, y_train):\n                X_tr, X_val = X_train[train_idx], X_train[val_idx]\n                y_tr, y_val = y_train[train_idx], y_train[val_idx]\n                \n                model = copy.deepcopy(self.estimator)\n                model.set_params(**params)\n                model.fit(X_tr, y_tr)\n                y_pred = model.predict(X_val)\n                \n                # Calcular la puntuación utilizando el scorer\n                score = self.scoring(y_val, y_pred)\n                \n                scores.append(score)\n            fitness = cp.mean(cp.array(scores))\n            fitnesses.append(fitness)\n        return cp.array(fitnesses)\n\n    def select_parents(self, population, fitnesses):\n        selected = []\n        for _ in range(len(population)):\n            indices = cp.random.randint(0, len(population), size=self.tournament_size)\n            best_idx = indices[cp.argmax(fitnesses[indices])]\n            selected.append(population[best_idx])\n        return cp.vstack(selected)\n\n    def crossover(self, parents, crossover_rate):\n        offspring = []\n        for i in range(0, len(parents), 2):\n            parent1 = parents[i].copy()\n            parent2 = parents[(i+1) % len(parents)].copy()\n            if cp.random.rand() < crossover_rate:\n                point = cp.random.randint(1, len(parent1))\n                child1 = cp.concatenate((parent1[:point], parent2[point:]))\n                child2 = cp.concatenate((parent2[:point], parent1[point:]))\n                offspring.append(child1)\n                offspring.append(child2)\n            else:\n                offspring.append(parent1)\n                offspring.append(parent2)\n        return cp.vstack(offspring)\n\n    def mutate(self, offspring, mutation_rate, mutation_scale=0.1):\n        for chromosome in offspring:\n            if cp.random.rand() < mutation_rate:\n                gene_idx = cp.random.randint(0, len(chromosome))\n                mutation = cp.random.normal(0, mutation_scale)\n                chromosome[gene_idx] += mutation\n                chromosome[gene_idx] = cp.clip(chromosome[gene_idx], 0.0, 1.0)\n        return offspring\n\n    def generate_random_individuals(self, n_random):\n        chromosome_length = len(self.param_grid)\n        random_chromosomes = cp.empty((n_random, chromosome_length), dtype=cp.float32)\n        for i, key in enumerate(self.param_grid.keys()):\n            grid = self.param_grid[key]\n            low = grid['low']\n            high = grid['high']\n            if grid['type'] == 'int':\n                sampled = cp.random.randint(low, high + 1, size=n_random)\n                normalized = (sampled - low) / (high - low)\n                random_chromosomes[:, i] = normalized.astype(cp.float32)\n            elif grid['type'] == 'float':\n                sampled = cp.random.uniform(low, high, size=n_random)\n                normalized = (sampled - low) / (high - low)\n                random_chromosomes[:, i] = normalized.astype(cp.float32)\n            else:\n                raise ValueError(f\"Tipo de parámetro no soportado: {grid['type']}\")\n        return random_chromosomes\n\n    def fit(self, X_train, y_train):\n        if self.cv is None:\n            self.cv = StratifiedKFold(n_splits=5, shuffle=True)\n        chromosome_length = len(self.param_grid)\n        population = self.initialize_population()\n        best_overall_fitness = -cp.inf\n        best_overall_chromosome = None\n        no_improvement_generations = 0\n\n        for generation in range(self.generations):\n            if self.verbose:\n                print(f\"Generación [{generation+1}]\")\n            crossover_rate = self.crossover_initial * ((self.crossover_end / self.crossover_initial) ** (generation / self.generations))\n            mutation_rate = self.mutation_initial * ((self.mutation_end / self.mutation_initial) ** (generation / self.generations))\n            if self.verbose:\n                print(f\"Crossover Rate: {crossover_rate:.4f}, Mutation Rate: {mutation_rate:.4f}\")\n            fitnesses = self.evaluate_population(population, X_train, y_train)\n            current_best_fitness = cp.max(fitnesses)\n            if self.verbose:\n                print(f\"Mejor fitness en generación [{generation+1}]: {current_best_fitness}\")\n            if current_best_fitness > best_overall_fitness:\n                best_overall_fitness = current_best_fitness\n                best_idx = cp.argmax(fitnesses)\n                best_overall_chromosome = population[best_idx]\n                no_improvement_generations = 0\n            else:\n                no_improvement_generations += 1\n            if no_improvement_generations >= self.early_stopping_rounds:\n                if self.verbose:\n                    print(f\"No hubo mejora en el fitness por {self.early_stopping_rounds} generaciones consecutivas. Deteniendo el algoritmo.\")\n                    print(f\"El mejor fitness: {best_overall_fitness}\")\n                break\n            if self.elitism:\n                sorted_indices = cp.argsort(fitnesses)[::-1]\n                elites = population[sorted_indices[:self.elite_size]]\n            else:\n                elites = None\n            # Seleccionar padres\n            parents = self.select_parents(population, fitnesses)\n            # Generar descendencia mediante cruza\n            offspring = self.crossover(parents, crossover_rate=crossover_rate)\n            # Aplicar mutaciones a la descendencia\n            offspring = self.mutate(offspring, mutation_rate=mutation_rate)\n            # Inyección de individuos aleatorios\n            random_individuals = self.generate_random_individuals(self.n_random)\n            offspring = cp.vstack((offspring, random_individuals))\n            # Mantener el tamaño de la población\n            if self.elitism and elites is not None:\n                population = cp.vstack((elites, offspring))\n            else:\n                population = offspring\n            # Si la población excede el tamaño, seleccionar los mejores\n            if len(population) > self.pop_size:\n                fitnesses = self.evaluate_population(population, X_train, y_train)\n                sorted_indices = cp.argsort(fitnesses)[::-1]\n                population = population[sorted_indices[:self.pop_size]]\n                    \n        self.best_params_ = self.decode_chromosome(best_overall_chromosome)\n        self.best_score_ = best_overall_fitness.get()\n        return self","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:01.961813Z","iopub.execute_input":"2024-10-31T13:03:01.962166Z","iopub.status.idle":"2024-10-31T13:03:02.002941Z","shell.execute_reply.started":"2024-10-31T13:03:01.962129Z","shell.execute_reply":"2024-10-31T13:03:02.001743Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Entrenar los modelos","metadata":{}},{"cell_type":"code","source":"def train_model_buy(X_train, y_train, param_grid):\n    try:\n        # Definir el pipeline con placeholders\n        estimator = Pipeline([\n            ('scaler', StandardScaler()),\n            ('dim_reducer', PCA()),\n            ('xgb', xgb.XGBClassifier(eval_metric='mlogloss', tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0))\n        ])\n        # Crear una instancia de GeneticAlgorithmCV\n        ga_search = GeneticAlgorithmCV(\n            estimator=estimator,\n            param_grid=param_grid,\n            cv=StratifiedKFold(n_splits=5, shuffle=True),\n            scoring=accuracy_score,\n            pop_size=50,\n            generations=15,\n            tournament_size=3,\n            crossover_initial=0.1,\n            crossover_end=0.9,\n            mutation_initial=0.9,\n            mutation_end=0.1,\n            elitism=True,\n            elite_size=5,\n            early_stopping_rounds=1,\n            n_random=10,\n            verbose=True\n        )\n        # Entrenar el modelo utilizando el algoritmo genético\n        ga_search.fit(X_train, y_train)\n    except Exception as e:\n        print(f\"Error en train_model_buy: {e}\")\n        raise\n    # Obtener los mejores parámetros y el mejor estimador\n    best_params = ga_search.best_params_\n    print(\"Mejores parámetros encontrados para compras:\", best_params)\n    print(\"Mejor puntuación de validación para compras:\", ga_search.best_score_)\n    # Retornar mejores parámetros\n    return best_params","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:02.004347Z","iopub.execute_input":"2024-10-31T13:03:02.004776Z","iopub.status.idle":"2024-10-31T13:03:02.020932Z","shell.execute_reply.started":"2024-10-31T13:03:02.004727Z","shell.execute_reply":"2024-10-31T13:03:02.019867Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train_model_sell(X_train, y_train, param_grid):\n    try:\n        # Definir el pipeline con placeholders\n        estimator = Pipeline([\n            ('scaler', StandardScaler()),\n            ('dim_reducer', PCA()),\n            ('xgb', xgb.XGBClassifier(eval_metric='mlogloss', tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0))\n        ])\n        # Crear una instancia de GeneticAlgorithmCV\n        ga_search = GeneticAlgorithmCV(\n            estimator=estimator,\n            param_grid=param_grid,\n            cv=StratifiedKFold(n_splits=5, shuffle=True),\n            scoring=accuracy_score,\n            pop_size=50,\n            generations=15,\n            tournament_size=3,\n            crossover_initial=0.1,\n            crossover_end=0.9,\n            mutation_initial=0.9,\n            mutation_end=0.1,\n            elitism=True,\n            elite_size=5,\n            early_stopping_rounds=1,\n            n_random=10,\n            verbose=True\n        )\n        # Entrenar el modelo utilizando el algoritmo genético\n        ga_search.fit(X_train, y_train)\n    except Exception as e:\n        print(f\"Error en train_model_buy: {e}\")\n        raise\n    # Obtener los mejores parámetros y el mejor estimador\n    best_params = ga_search.best_params_\n    print(\"Mejores parámetros encontrados para compras:\", best_params)\n    print(\"Mejor puntuación de validación para compras:\", ga_search.best_score_)\n    # Retornar mejores parámetros\n    return best_params","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:02.022694Z","iopub.execute_input":"2024-10-31T13:03:02.023351Z","iopub.status.idle":"2024-10-31T13:03:02.033525Z","shell.execute_reply.started":"2024-10-31T13:03:02.023306Z","shell.execute_reply":"2024-10-31T13:03:02.032666Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Definir param_grid con rangos\nparam_grid = {\n    'dim_reducer__n_components': {'type': 'int', 'low': 2, 'high': n_features},\n    'xgb__n_estimators': {'type': 'int', 'low': 50, 'high': 500},\n    'xgb__max_depth': {'type': 'int', 'low': 3, 'high': 10},\n    'xgb__learning_rate': {'type': 'float', 'low': 0.01, 'high': 0.3},\n    'xgb__subsample': {'type': 'float', 'low': 0.6, 'high': 1.0},\n    'xgb__colsample_bytree': {'type': 'float', 'low': 0.6, 'high': 1.0},\n    'xgb__gamma': {'type': 'float', 'low': 0.0, 'high': 0.5},\n    'xgb__min_child_weight': {'type': 'int', 'low': 1, 'high': 10},\n    'xgb__reg_alpha': {'type': 'float', 'low': 0.0, 'high': 1.0},\n    'xgb__reg_lambda': {'type': 'float', 'low': 0.0, 'high': 1.0}\n}","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:02.034694Z","iopub.execute_input":"2024-10-31T13:03:02.035009Z","iopub.status.idle":"2024-10-31T13:03:02.045655Z","shell.execute_reply.started":"2024-10-31T13:03:02.034960Z","shell.execute_reply":"2024-10-31T13:03:02.044547Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Entrenar modelos simultáneamente\nwith ThreadPoolExecutor(max_workers=2) as executor:\n    # enviar tareas de entrenamiento\n    future_buy = executor.submit(train_model_buy, X_buy_train, y_buy_train, param_grid)\n    future_sell = executor.submit(train_model_sell, X_sell_train, y_sell_train, param_grid)\n    # esperar a que todas las tareas terminen\n    futures = [future_buy, future_sell]\n    print(\"Esperando que las tareas finalicen...\")\n    wait(futures)\n    print(\"¡Todas las tareas han terminado!\")\n    # Obtener resultados una vez que ambas tareas han terminado\n    model_buy_best_params = future_buy.result()\n    model_sell_best_params = future_sell.result()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:03:02.048901Z","iopub.execute_input":"2024-10-31T13:03:02.049240Z","iopub.status.idle":"2024-10-31T13:50:06.942017Z","shell.execute_reply.started":"2024-10-31T13:03:02.049206Z","shell.execute_reply":"2024-10-31T13:50:06.940978Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Generación [1]\nCrossover Rate: 0.1000, Mutation Rate: 0.9000\nEsperando que las tareas finalicen...\nGeneración [1]\nCrossover Rate: 0.1000, Mutation Rate: 0.9000\nMejor fitness en generación [1]: 0.5274966955184937\nMejor fitness en generación [1]: 0.5615351676940918\nGeneración [2]\nCrossover Rate: 0.1158, Mutation Rate: 0.7774\nGeneración [2]\nCrossover Rate: 0.1158, Mutation Rate: 0.7774\nMejor fitness en generación [2]: 0.5327566981315612\nMejor fitness en generación [2]: 0.5661045670509338\nGeneración [3]\nCrossover Rate: 0.1340, Mutation Rate: 0.6714\nMejor fitness en generación [3]: 0.5336851596832275\nGeneración [3]\nCrossover Rate: 0.1340, Mutation Rate: 0.6714\nGeneración [4]\nCrossover Rate: 0.1552, Mutation Rate: 0.5800\nMejor fitness en generación [3]: 0.5647263884544372\nNo hubo mejora en el fitness por 1 generaciones consecutivas. Deteniendo el algoritmo.\nEl mejor fitness: 0.5661045670509338\nMejores parámetros encontrados para compras: {'xgb__n_estimators': 248, 'xgb__max_depth': 6, 'xgb__learning_rate': array(0.01553191), 'xgb__subsample': array(0.80621272), 'xgb__colsample_bytree': array(0.71296732), 'xgb__gamma': array(0.42364436), 'xgb__min_child_weight': 8, 'xgb__reg_alpha': array(0.7978957), 'xgb__reg_lambda': array(0.89894214)}\nMejor puntuación de validación para compras: 0.5661045670509338\nMejor fitness en generación [4]: 0.5352985382080078\nGeneración [5]\nCrossover Rate: 0.1797, Mutation Rate: 0.5009\nMejor fitness en generación [5]: 0.5373553991317749\nGeneración [6]\nCrossover Rate: 0.2080, Mutation Rate: 0.4327\nMejor fitness en generación [6]: 0.5341570019721985\nNo hubo mejora en el fitness por 1 generaciones consecutivas. Deteniendo el algoritmo.\nEl mejor fitness: 0.5373553991317749\nMejores parámetros encontrados para compras: {'xgb__n_estimators': 245, 'xgb__max_depth': 3, 'xgb__learning_rate': array(0.01), 'xgb__subsample': array(0.62516104), 'xgb__colsample_bytree': array(0.6259701), 'xgb__gamma': array(0.43366633), 'xgb__min_child_weight': 7, 'xgb__reg_alpha': array(0.99656668), 'xgb__reg_lambda': array(0.0289573)}\nMejor puntuación de validación para compras: 0.5373553991317749\n¡Todas las tareas han terminado!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Entrenar modelos para ONNX","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:50:06.944446Z","iopub.execute_input":"2024-10-31T13:50:06.944874Z","iopub.status.idle":"2024-10-31T13:50:06.952954Z","shell.execute_reply.started":"2024-10-31T13:50:06.944830Z","shell.execute_reply":"2024-10-31T13:50:06.952006Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Definir el pipeline con placeholders para compras\nmodel_buy = Pipeline([\n    ('scaler', StandardScaler()),\n    ('dim_reducer', PCA()),\n    ('xgb', xgb.XGBClassifier(eval_metric='mlogloss', tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0))\n])\nmodel_buy.set_params(**model_buy_best_params)\nmodel_buy.fit(X_buy_train.get(), y_buy_train.get())\n# Definir el pipeline con placeholders para ventas\nmodel_sell = Pipeline([\n    ('scaler', StandardScaler()),\n    ('dim_reducer', PCA()),\n    ('xgb', xgb.XGBClassifier(eval_metric='mlogloss', tree_method='gpu_hist', predictor='gpu_predictor', verbosity=0))\n])\nmodel_sell.set_params(**model_sell_best_params)\nmodel_sell.fit(X_sell_train.get(), y_sell_train.get())","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:59:01.451233Z","iopub.execute_input":"2024-10-31T13:59:01.452246Z","iopub.status.idle":"2024-10-31T13:59:02.561565Z","shell.execute_reply.started":"2024-10-31T13:59:01.452196Z","shell.execute_reply":"2024-10-31T13:59:02.560460Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('scaler', StandardScaler()),\n                ('xgb',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=array(0.6259701), device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric='mlogloss',\n                               feature_types=None, gamma=array(0.43366633),\n                               grow_policy=None, importance_type=None,\n                               interaction_constraints=None,\n                               learning_rate=array(0.01), max_bin=None,\n                               max_cat_threshold=None, max_cat_to_onehot=None,\n                               max_delta_step=None, max_depth=3,\n                               max_leaves=None, min_child_weight=7, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=245, n_jobs=None,\n                               num_parallel_tree=None,\n                               predictor='gpu_predictor', ...))])","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=array(0.6259701), device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n                               feature_types=None, gamma=array(0.43366633),\n                               grow_policy=None, importance_type=None,\n                               interaction_constraints=None,\n                               learning_rate=array(0.01), max_bin=None,\n                               max_cat_threshold=None, max_cat_to_onehot=None,\n                               max_delta_step=None, max_depth=3,\n                               max_leaves=None, min_child_weight=7, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=245, n_jobs=None,\n                               num_parallel_tree=None,\n                               predictor=&#x27;gpu_predictor&#x27;, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;xgb&#x27;,\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=array(0.6259701), device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n                               feature_types=None, gamma=array(0.43366633),\n                               grow_policy=None, importance_type=None,\n                               interaction_constraints=None,\n                               learning_rate=array(0.01), max_bin=None,\n                               max_cat_threshold=None, max_cat_to_onehot=None,\n                               max_delta_step=None, max_depth=3,\n                               max_leaves=None, min_child_weight=7, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=245, n_jobs=None,\n                               num_parallel_tree=None,\n                               predictor=&#x27;gpu_predictor&#x27;, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=array(0.6259701), device=None,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=&#x27;mlogloss&#x27;, feature_types=None,\n              gamma=array(0.43366633), grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=array(0.01),\n              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=3, max_leaves=None,\n              min_child_weight=7, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=245, n_jobs=None,\n              num_parallel_tree=None, predictor=&#x27;gpu_predictor&#x27;, ...)</pre></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Exportar modelos a formato ONNX","metadata":{}},{"cell_type":"code","source":"def save_onnx_models(kaggle_output_folder):\n    try:\n        update_registered_converter(\n            xgb.XGBClassifier,\n            \"XGBClassifier\",\n            calculate_linear_classifier_output_shapes,\n            convert_xgboost,\n            options={'nocl': [True, False], 'zipmap': [True, False, 'columns']}\n        )\n        model_buy_onnx = convert_sklearn(\n            model_buy,\n            'pipeline_buy_xgboost',\n            [('input', FloatTensorType([None, X_buy_train.shape[1]]))],\n            target_opset={'': 12, 'ai.onnx.ml': 2}\n        )\n        model_sell_onnx = convert_sklearn(\n            model_sell,\n            'pipeline_sell_xgboost',\n            [('input', FloatTensorType([None, X_buy_train.shape[1]]))],\n            target_opset={'': 12, 'ai.onnx.ml': 2}\n        )\n        with open(os.path.join(kaggle_output_folder, \"model_buy.onnx\"), 'wb') as f:\n            f.write(model_buy_onnx.SerializeToString())\n        with open(os.path.join(kaggle_output_folder, \"model_sell.onnx\"), 'wb') as f:\n            f.write(model_sell_onnx.SerializeToString())\n    except Exception as e:\n        print(f\"Error en exportar los modelos: {e}\")\n        raise\n    print(\"Modelos ONNX exportados correctamente\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:59:06.349262Z","iopub.execute_input":"2024-10-31T13:59:06.350304Z","iopub.status.idle":"2024-10-31T13:59:06.362004Z","shell.execute_reply.started":"2024-10-31T13:59:06.350256Z","shell.execute_reply":"2024-10-31T13:59:06.360890Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"kaggle_output_folder = r'/kaggle/working/'\n# Exportar modelos\nsave_onnx_models(kaggle_output_folder)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:59:07.408060Z","iopub.execute_input":"2024-10-31T13:59:07.408488Z","iopub.status.idle":"2024-10-31T13:59:07.791692Z","shell.execute_reply.started":"2024-10-31T13:59:07.408441Z","shell.execute_reply":"2024-10-31T13:59:07.790702Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Modelos ONNX exportados correctamente\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}